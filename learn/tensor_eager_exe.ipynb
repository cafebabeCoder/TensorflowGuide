{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workPlace\\gitCode\\python-lorineluo-dev\\src\\main\\python\\dnnr\\model\\model.ckpt-100\n"
     ]
    }
   ],
   "source": [
    "latest_checkpoint = tf.train.latest_checkpoint(\"D:\\workPlace\\gitCode\\python-lorineluo-dev\\src\\main\\python\\dnnr\\model\")\n",
    "print(latest_checkpoint)\n",
    "reader = tf.train.NewCheckpointReader(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reader' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4b9fbc2ac1b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input_layer/cate2_cate2_lst_weight_info_cate2_weight_info_shared_embedding/embedding_weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reader' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "reader.get_tensor(\"input_layer/cate2_cate2_lst_weight_info_cate2_weight_info_shared_embedding/embedding_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  dense/kernel\ntensor_name:  beta1_power\ntensor_name:  beta2_power\ntensor_name:  weights/Adam_1\ntensor_name:  input_layer/media_media_lst_weight_info_media_weight_info_shared_embedding/embedding_weights\ntensor_name:  dense/bias\ntensor_name:  bias\ntensor_name:  weights\ntensor_name:  input_layer/media_media_lst_weight_info_media_weight_info_shared_embedding/embedding_weights/Adam_1\ntensor_name:  dense/bias/Adam_1\ntensor_name:  input_layer/media_media_lst_weight_info_media_weight_info_shared_embedding/embedding_weights/Adam\ntensor_name:  dense/bias/Adam\ntensor_name:  bias/Adam_1\ntensor_name:  bias/Adam\ntensor_name:  dense/kernel/Adam\ntensor_name:  dense_1/bias/Adam\ntensor_name:  dense/kernel/Adam_1\ntensor_name:  dense_1/bias\ntensor_name:  dense_1/bias/Adam_1\ntensor_name:  dense_1/kernel\ntensor_name:  input_layer/tag_tag_lst_weight_info_tag_weight_info_shared_embedding/embedding_weights/Adam_1\ntensor_name:  dense_1/kernel/Adam\ntensor_name:  input_layer/tag_tag_lst_weight_info_tag_weight_info_shared_embedding/embedding_weights/Adam\ntensor_name:  dense_1/kernel/Adam_1\ntensor_name:  input_layer/dev_mode_embedding/embedding_weights/Adam\ntensor_name:  input_layer/city_embedding/embedding_weights\ntensor_name:  dense_2/bias\ntensor_name:  input_layer/city_embedding/embedding_weights/Adam\ntensor_name:  dense_2/kernel\ntensor_name:  dense_2/bias/Adam\ntensor_name:  input_layer/city_embedding/embedding_weights/Adam_1\ntensor_name:  dense_2/bias/Adam_1\ntensor_name:  dense_2/kernel/Adam\ntensor_name:  dense_2/kernel/Adam_1\ntensor_name:  global_step\ntensor_name:  input_layer/days3vids_days7vids_daysvids_hoursvids_vid_shared_embedding/embedding_weights/Adam_1\ntensor_name:  input_layer/cate2_cate2_lst_weight_info_cate2_weight_info_shared_embedding/embedding_weights\ntensor_name:  input_layer/cate2_cate2_lst_weight_info_cate2_weight_info_shared_embedding/embedding_weights/Adam_1\ntensor_name:  input_layer/cate2_cate2_lst_weight_info_cate2_weight_info_shared_embedding/embedding_weights/Adam\ntensor_name:  input_layer/days3vids_days7vids_daysvids_hoursvids_vid_shared_embedding/embedding_weights\ntensor_name:  input_layer/days3vids_days7vids_daysvids_hoursvids_vid_shared_embedding/embedding_weights/Adam\ntensor_name:  input_layer/dev_mode_embedding/embedding_weights\ntensor_name:  input_layer/dev_mode_embedding/embedding_weights/Adam_1\ntensor_name:  input_layer/devid_embedding/embedding_weights\ntensor_name:  input_layer/devid_embedding/embedding_weights/Adam\ntensor_name:  input_layer/devid_embedding/embedding_weights/Adam_1\ntensor_name:  input_layer/tag_tag_lst_weight_info_tag_weight_info_shared_embedding/embedding_weights\ntensor_name:  weights/Adam\n"
     ]
    }
   ],
   "source": [
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "for key in var_to_shape_map:\n",
    "    print(\"tensor_name: \", key)\n",
    "    #print(reader.get_tensor(key)) # Remove this is you want to print only variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[[1,2,3]],[[5,4,9]],[[12,23,134]],[[11,15,8]],[[201,123,23]]] )\n",
    "y.shape\n",
    "yf = tf.add(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tf.reshape(yf, [-1, 3])\n",
    "tf.shape(m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(3, 1), dtype=int32, numpy=\narray([[1],\n       [1],\n       [0]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd = [[3],[2],[0]]\n",
    "x=tf.div(nd, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1a44ae377d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "nd = [[1],[1],[0]]\n",
    "tmp=tf.reshape(tf.range(0,tf.shape(m)[0]-2,1), [3,1])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57690, shape=(3, 2), dtype=int32, numpy=\narray([[0, 1],\n       [1, 1],\n       [2, 0]])>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=tf.concat([tmp, nd], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57697, shape=(3,), dtype=int32, numpy=array([ 3,  5, 13])>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57654, shape=(3,), dtype=int32, numpy=array([ 3,  5, 13])>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,0]] )\n",
    "logits = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y = np.array(y).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=56887, shape=(5611,), dtype=float64, numpy=\narray([  5.1294e-07,   8.9997e-12,   2.2176e-08, ...,   2.7045e-04,\n         1.7630e-06,   4.1695e-08])>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = np.array([0.103125,-0.444411,-0.0539319,-0.0289775,-0.0346578,0.218666,-0.307558,0.30258,0.285907,-0.0903464,-0.101131,0.0130939,-0.263416,0.144347,-0.188386,0.0155433,0.187846,0.0167575,-0.0621931,-0.267283,-0.125263,0.110297,-0.230813,-0.170979,-0.293915,0.225792,-0.0989381,-0.0288575,-0.346357,0.267817,0.0178661,0.0792406,-0.187977,-0.219319,0.0404169,0.0933204,0.114182,-0.0579446,0.0458545,-0.0513846,0.212579,0.0727439,-0.0419479,-0.263322,-0.118886,-0.14571,-0.372236,0.336813,-0.357476,-0.35628,-0.0742699,-0.0745243,0.00746316,0.106144,0.0903497,0.12502,-0.137165,-0.0394196,-0.159144,-0.132731,-0.075315,-0.129509,-0.113429,-0.0756837,-0.437935,-0.148783,-0.0605029,-0.379813,-0.139618,-0.162393,0.260874,-0.0475663,-0.34753,-0.100238,0.0384393,0.154785,0.00955291,-0.0372035,0.229706,-0.0177956,-0.354206,-0.0482839,0.0455015,0.418414,-0.371203,-0.244292,-0.336216,0.170072,0.235114,0.0778707,-0.37319,-0.0304357,-0.120101,-0.0708999,-0.00075735,-0.285022,-0.20174,-0.0702491,0.224938,-0.155792,-0.222682,-0.0334788,-0.41213,0.184401,0.121972,0.0331164,-0.109749,0.0951,0.186724,0.238887,-0.234647,0.279515,0.212001,-0.352836,0.0892963,-0.313176,0.0226511,0.0351725,0.285555,0.0555175,0.097338,0.159287,-0.0365519,0.213318,0.220707,-0.357127,0.0238803,-0.398037,0.358101,-0.074543,-0.299693,-0.147731,-0.0608773,-0.362261,-0.203518,0.0718085,-0.0813816,0.0799626,0.0307114,-0.0771257,0.0733274,-0.0346567,-0.468371,-0.212503,-0.154744,0.230491,0.073464,-0.0447906,0.253397,-0.104261,0.254809,0.0368873,-0.238909,0.210845,0.0544598,0.0752661,0.345192,0.0614856,0.0457516,0.0251362,-0.0284729,0.166754,-0.378057,-0.0596107,-0.0733474,-0.0705256,0.218452,-0.351824,0.108071,0.121342,-0.0327658,-0.00616665,-0.37505,0.351978,-0.146781,-0.519419,-0.136254,-0.125955,0.00259842,-0.293551,0.106666,-0.206219,0.310227,0.110747,0.168204,0.0546333,0.209535,-0.110001,0.181864,-0.0380698,-0.295043,0.14309,0.0632132,0.0430088,0.105007,-0.125452,-0.269743,0.247366,-0.0498933,0.355815,0.0126585,0.0293821,-0.0944464,0.0480991,0.0284959,0.0610429,-0.332388,0.500897,-0.396323,-0.10428,0.167359,-0.0953053,0.263431,-0.0448004,0.0766852,-0.263328,0.210802,-0.217344,0.132005,-0.331032,-0.0571617,-0.0614998,0.132739,-0.0795299,-0.112066,0.0471495,-0.141121,-0.0178467,-0.0250321,-0.00501495,-0.00413196,0.3044,0.403853,0.202023,0.0484624,0.213719,0.068897,0.0581382,-0.394732,-0.055901,-0.300961,0.123463,-0.117805,-0.23023,0.0169594,-0.167089,0.198947,0.327817,0.346267,0.366251,-0.184849,-0.153002,-0.331226,-0.0675033,-0.241211,0.0351,-0.0764371,0.237178,0.223814,-0.211656,-0.197041,-0.618826,0.117133,-0.116308,-0.0134228,-0.0254093,-0.61739,0.305237,0.287106,-0.117013,0.0399749,0.373558,0.254312,-0.180306,-0.256447,-0.0726378,-0.422775,-0.106164,-0.0405329,-0.452304,0.121735,0.151341,0.0268795,0.226764,0.0966974,0.166626,-0.0892059,-0.0359038,0.0587682,0.0131039,-0.0448811,-0.277506,-0.0761523,-0.122206,-0.022137,0.03454,0.0221865,-0.211577,0.276936,0.225358,-0.270613,0.173895,-0.0476687,0.0224974,0.0904756,0.138427,0.103259,0.050184,-0.380685,-0.26444,0.462579,0.247071,0.190603,0.0143084,-0.0220882,-0.155125,0.376811,-0.0192256,-0.0119277,0.333421,0.0676342,0.371509,0.314857,-0.129709,-0.426909,0.265925,0.247913,0.205295,0.25631,-0.115089,-0.312846,0.314968,0.255543,-0.0188399,0.175573,-0.344582,0.163729,-0.419363,0.210804,0.404287,0.148969,-0.101545,0.240991,0.229302,-0.0859358,-0.337197,-0.0202118,-0.252413,-0.0860786,-0.184778,0.113341,-0.255724,0.0257283,0.0894221,0.0354973,0.0673914,-0.258958,0.491726,0.407057,0.209778,-0.0947539,0.17514,-0.0123689,0.164785,0.0320485,0.41548,0.122756,0.109894,0.0855523,-0.126628,0.0855309,-0.21313,-0.156045,-0.170971,0.0996183,0.0168442,-0.257263,0.0651333,0.120727,-0.115951,-0.0787428,0.331917,0.444758,0.220872,0.162258,0.0945232,0.088019,0.189767,-0.037847,-0.100843,0.129548,0.241425,0.149465,0.289247,0.215721,0.0858229,0.543767,-0.0331282,-0.0305435,0.111637,0.127512,-0.41714,-0.101979,0.310414,0.346567,-0.18377,0.150946,0.352075,-0.255711,-0.0224745,-0.162113,0.276184,-0.0198369,0.094711,0.0319608,0.10343,0.318638,0.0193659,0.420326,0.168717,0.190591,0.152562,0.19122,0.491165,-0.168853,-0.290463,0.425904,0.158337,0.131625,-0.46517,-0.0425052,-0.262886,-0.0895363,-0.137292,-0.0531574,0.264746,0.0995663,0.215,-0.16718,0.298162,-0.0396484,-0.050932,0.407762,0.485328,0.453441,-0.105516,0.0750641,-0.258508,-0.0261693,-0.0633427,-0.168423,0.00490227,-0.201103,0.463623,-0.329977,-0.0625192,-0.418508,-0.0755705,0.187394,-0.0456725,-0.249521,-0.0847558,0.0112519,0.145552,-0.159154,-0.0340334,-0.0753635,-0.0614892,0.232856,-0.125409,-0.093909,-0.148004,0.0958012,-0.230561,0.518943,-0.236044,-0.387309,-0.207371,-0.0472902,-0.0784627,0.0917652,0.0485374,0.496827,-0.110961,0.141327,-0.275839,0.350875,-0.0897744,-0.257088,0.0350478,0.0460664,0.26999,0.248216,0.316504,-0.0247781,0.152856,-0.140817,0.499628,0.282705,0.188776,0.0144464,0.168518,0.1384,-0.0208253,0.185329,-0.152283,-0.0372519,-0.0599726,-0.139785,-0.00795547,0.0586256,-0.0456171,-0.113512,-0.135451,0.0233541,0.199191,-0.267937,-0.000628337,-0.0300293,0.38794,0.128535,0.10216,0.0946919,0.205438,0.0802644,0.123401,0.0180813,-0.0800664,0.100336,-0.235988,0.140969,0.0944003,-0.0477361,-0.131732,0.0252707,-0.0259838,-0.00341536,0.0956314,-0.31557,0.21218,0.261538,0.0734434,-0.086022,0.175941,0.247101,0.104106,-0.122443,-0.0178621,-0.103989,-0.2244,0.201056,-0.261248,-0.0185265,0.00995758,-0.159694,0.0740156,0.0398868,0.116406,0.059412,0.110865,0.155578,-0.313634,0.0574419,0.162088,-0.035666,-0.111825,0.081647,0.0124401,-0.053389,0.0635833,0.178069,-0.17748,-0.349073,0.0604652,-0.0347715,-0.0103687,0.280995,0.320197,0.137269,-0.259274,0.243153,-0.074811,0.0477882,-0.0686722,-0.0509858,-0.0873988,-0.309154,-0.165671,0.129905,0.206018,-0.214622,-0.156575,0.144742,-0.125371,-0.0763514,-0.0609897,0.242358,-0.293173,-0.248828,0.356431,-0.400362,0.0712991,0.284039,-0.239981,-0.070568,-0.00649785,-0.466512,-0.136935,-0.138061,-0.120242,0.00502055,0.139994,-0.034618,-0.247499,0.305565,0.109337,0.0872313,0.0439454,-0.467048,0.00391368,0.182317,0.444872,0.0851943,0.132724,-0.182266,-0.0985708,-0.284513,-0.107268,-0.142869,0.056407,-0.0520528,-0.396607,-0.119174,0.0650017,0.0490483,-0.0374448,0.457616,-0.269222,-0.0846604,0.14748,-0.0832472,0.139429,-0.196472,-0.32511,-0.310362,0.219959,0.376056,0.241161,0.058463,-0.178845,0.311778,0.156038,0.229244,-0.215922,0.221851,-0.125061,0.0760347,0.0624802,0.196879,-0.00916459,0.0448661,0.313375,-0.00764859,-0.242195,-0.138337,-0.0499452,0.146982,0.169712,-0.508397,0.231883,-0.0522369,-0.325062,0.104466,0.139583,-0.159327,0.270526,-0.20419,0.0451792,-0.251735,-0.134121,0.360584,-0.598813,0.0315051,0.332397,-0.150896,0.484535,-0.127955,0.0737321,0.108348,0.236026,0.0163751,-0.247781,0.105505,0.190132,0.0788696,0.452836,0.0362903,-0.057312,0.260628,0.0570901,-0.0878564,0.417265,0.0462661,-0.0151522,-0.0157181,0.339094,-0.148956,-0.386434,-0.296593,-0.329882,0.211507,0.0072597,-0.307706,-0.176805,0.0323564,0.104869,0.77036,0.0694567,-0.563074,-0.437472,-0.141941,-0.0592849,0.220565,0.241223,-0.300767,0.188047,-0.446135,-0.367489,-0.0666648,-0.223197,-0.0754312,0.127593,-0.330988,0.0837807,0.0856461,0.00443061,-0.035761,-0.176385,0.488915,0.197764,0.235644,0.00836803,0.131299,0.163744,0.171681,0.261522,0.00383333,-0.160259,-0.276534,-0.0463776,0.0365169,-0.238765,-0.259848,-0.327978,0.155585,-0.355512,0.409133,0.49302,0.321164,-0.0404319,-0.186161,-0.0927955,-0.0630242,0.0528817,0.0743283,-0.30757,0.0651961,0.229089,0.240577,-0.35204,0.024392,0.162015,0.218821,-0.0382282,-0.199981,0.12976,0.02466,0.111552,0.143558,0.334556,-0.0961954,-0.137704,-0.181376,0.257765,0.171979,-0.06061,-0.406885,-0.0497927,-0.158974,0.0787121,-0.0215056,-0.450065,0.203681,-0.209857,-0.255533,-0.231357,0.281658,-0.0485976,-0.408095,-0.0922895,0.0029214,-0.158436,0.187645,-0.0987412,-0.017439,-0.0132855,-0.0354911,0.17977,-0.232769,-0.407954,-0.195325,0.022654,-0.315107,0.2675,0.0982916,-0.0858208,-0.243428,0.255287,-0.156412,0.00177383,-0.108331,0.0134364,0.242671,-0.143331,0.186246,-0.255228,0.189454,-0.207613,0.536454,0.0587994,-0.0248309,0.018383,-0.0307204,0.344813,0.00604112,-0.110366,-0.0912538,0.148332,0.311091,0.387978,-0.0595179,-0.113676,-0.0542646,-0.0782837,0.0496971,-0.142137,0.107279,-0.591193,-0.173931,-0.0868614,-0.306914,-0.127868,0.0519496,-0.100916,-0.2374,0.0545552,0.208455,-0.0766615,-0.29605,0.097503,-0.216145,0.116306,-0.129265,0.0992354,-0.216037,0.0956291,0.0198444,0.0339042,-0.22496,-0.0339505,0.0991212,0.173996,0.024138,0.1286,0.0562232,0.276632,0.233643,-0.080493,-0.186098,-0.0102927,-0.0468782,-0.462618,-0.310665,-0.201293,0.224416,0.0565361,-0.234876,0.344331,0.101946,0.28797,-0.211365,0.366328,-0.202647,0.204094,0.438176,-0.0863173,-0.111298,0.367284,0.138096,0.0441066,-0.0548061,0.189116,-0.11445,-0.120411,-0.0340688,0.364413,0.0566802,-0.204963,-0.0417544,0.296573,-0.12288,0.00583688,0.118055,0.0391774,0.132796,0.0120277,-0.322237,-0.0117318,-0.228217,-0.0423847,-0.332589,-0.0952228,0.110229,-0.0650039,-0.164125,-0.552756,-0.0240092,0.0683061,-0.0536001,0.1806,0.200043,0.0799473,-0.00261186,-0.0862103,-0.122215,-0.0218181,0.031557,0.170443,-0.0612046,-0.52549,0.0216485,0.0411096,-0.0993341,-0.0697304,0.107278,0.0125823,0.117115,-0.209459,-0.0287717,-0.0177582,0.00528878,0.00417131,0.0490768,0.224977,-0.205182,0.386815,-0.268689,-0.356741,0.263658,0.0519063,-0.0480266,-0.412416,0.110397,-0.146381,-0.183239,-0.240465,-0.0677638,0.0430071,0.0737007,-0.0288525,0.400639,0.21135,0.0576193,0.169188,0.133044,0.194974,0.279421,0.0380348,0.172978,-0.0554014,0.0389384,0.469233,0.0418598,0.388392,-0.165403,0.156792,-0.147426,-0.241292,-0.0902703,0.354369,-0.00761889,0.294251,0.028796,0.171731,0.643649,-0.234962,-0.0795417,-0.0766138,-0.279861,0.146374,-0.153915,-0.156568,0.220541,-0.264769,0.262734,0.0782344,-0.0814793,-0.328732,0.00270779,-0.302663,-0.06769,-0.323829,-0.406253,-0.164756,0.200091,0.0464816,-0.0771851,0.222658,-0.212456,0.369022,0.157995,-0.208341,-0.151346,-0.161836,0.100204,0.0518452,0.193891,0.337237,0.0992367,0.347104,-0.095374,0.16031,0.253911,-0.167727,-0.0496311,-0.221155,-0.0281086,-0.0533322,-0.47912,0.474383,0.383829,0.109953,-0.284584,-0.18249,-0.143796,0.0725514,0.0562708,0.108083,-0.220915,-0.0267353,0.201807,-0.299147,-0.108229,0.159211,0.0119147,0.223604,-0.352528,-0.056134,0.0163817,0.295152,0.00604686,-0.330445,0.0572097,0.064,0.0314033,0.249996,0.337397,-0.203547,0.640313,-0.42428,-0.125882,-0.125064,0.428919,0.065176,-0.209221,-0.0843246,-0.14868,-0.149783,-0.18504,-0.0710452,-0.272966,-0.221893,0.440764,-0.158077,-0.299935,0.0386247,-0.115612,-0.0929956,0.241357,0.190657,0.0549494,0.296947,-0.495022,0.011743,0.215265,-0.0451888,0.133499,-0.237881,0.200487,0.0135301,-0.125171,-0.0664686,-0.106123,-0.283461,-0.318911,0.0306133,-0.113761,0.272724,0.0521282,-0.355853,-0.108825,-0.282582,0.050096,-0.114426,0.255986,0.185363,0.175468,0.0637592,-0.133051,0.131957,0.276379,-0.148549,0.223459,-0.154055,0.0995258,0.0180498,-0.19856,0.277519,0.265525,-0.0738768,0.145436,-0.311314,0.00116579,-0.178136,-0.0517306,0.234904,0.267827,0.100759,0.0905532,-0.177822,0.118317,-0.230967,0.31841,-0.00144386,-0.0604184,-0.197168,-0.00162969,-0.143214,-0.180114,-0.191091,0.239919,-0.23193,-0.405398,0.0910903,0.0575844,-0.116805,-0.10918,-0.362426,0.163802,0.412872,0.0376283,-0.44092,0.0732288,-0.0138912,0.0736642,0.0929083,-0.0178373,0.073219,0.483061,-0.111264,0.0606613,-0.0770373,-0.0455522,-0.0623292,-0.276175,-0.247419,-0.311753,0.294808,-0.0841067,-0.365235,-0.20529,0.0327243,0.0531914,-0.208823,0.183131,-0.162791,-0.177424,-0.0226052,-0.299108,-0.357812,0.407257,0.044557,0.098595,-0.154101,-0.0304404,0.311197,-0.0455975,-0.502794,0.0372249,0.151427,-0.216707,-0.145894,0.0882658,-0.253344,-0.122797,-0.314794,-0.104311,0.295948,-0.103333,0.23218,0.330465,-0.184156,0.0607889,0.0238112,-0.0880748,0.0269181,-0.157966,0.463299,0.372513,0.195002,-0.254795,0.110653,0.261532,0.300955,0.0626394,0.0939462,0.750468,0.170292,0.141073,0.378854,0.0668493,-0.0161633,0.169963,-0.288911,-0.061998,-0.0605956,0.162706,0.165568,-0.0150817,-0.129326,0.25941,-0.400755,0.152853,-0.10201,-0.172485,-0.295268,0.30101,0.0119601,0.0819678,0.300256,-0.0931737,-0.526784,-0.0221249,-0.328373,0.10952,0.418072,0.0631872,-0.0327429,-0.394689,-0.179342,0.261494,-0.107666,-0.130112,-0.143905,0.00881365,0.0574389,0.056113,0.224323,-0.0353882,0.587118,-0.102545,-0.052111,-0.0119276,-0.356882,-0.0492535,-0.68846,-0.314529,-0.189256,0.238991,0.385038,0.0187975,0.36363,0.1507,0.0045834,-0.081002,-0.303216,0.133993,-0.412576,-0.140105,0.270253,0.160429,-0.221688,0.101539,0.191966,0.0653498,-0.260497,0.261093,0.158953,0.00171195,-0.250924,0.0963343,-0.19883,0.233437,0.00595519,0.0566218,-0.0518864,0.123631,0.313909,-0.38393,0.0790134,-0.118553,0.0347532,-0.281447,-0.176549,-0.290311,-0.2395,-0.455877,0.276213,0.214316,0.131346,-0.144831,-0.594079,0.313926,-0.137296,-0.0319652,0.00353597,0.241147,0.205918,0.276509,-0.511508,0.164249,-0.0795402,0.28773,-0.126563,0.108861,-0.102798,-0.270574,0.20365,0.20565,-0.587556,-0.505486,0.135001,0.14517,-0.0553946,-0.231198,-0.0959331,-0.0386267,-0.151265,-0.0962213,0.420929,-0.230474,0.00813664,-0.2773,-0.422897,-0.114202,0.0278437,0.323203,-0.0057893,0.0339258,-0.189946,-0.194359,0.0627014,-0.0655291,-0.109899,0.0231586,0.0627251,0.0642428,0.0132113,-0.150158,-0.264765,-0.221707,0.415343,-0.452948,-0.166808,-0.229543,-0.082505,0.162624,-0.545363,-0.0696572,-0.222208,-0.0988794,0.637909,-0.163061,-0.253983,-0.0606511,-0.122341,0.245654,0.14061,-0.230866,-0.270321,0.466604,0.288415,0.109332,0.11018,0.273959,-0.0500255,-0.156058,0.179451,0.0500859,-0.0255581,-0.274217,0.334129,-0.225718,0.117376,-0.0265213,-0.210458,0.185354,0.211298,0.0154054,0.292452,-0.428517,-0.0213216,0.208281,-0.124143,-0.286562,0.00275473,0.146072,-0.0373117,-0.109451,-0.255564,0.0111218,0.273057,-0.152314,-0.138628,0.199782,0.325469,-0.123947,0.179224,0.0960966,0.0655469,0.0563915,-0.0488543,0.165786,0.209238,0.0706441,0.175934,-0.111541,-0.0272753,-0.381222,0.30651,-0.0481522,0.606394,-0.314836,-0.146786,0.156639,-0.129499,-0.425204,-0.283752,-0.101226,0.0752789,-0.124743,0.194749,-0.16911,0.258374,0.222515,0.143072,-0.0160373,0.200657,-0.0743418,-0.0452057,-0.0236249,0.189928,0.129079,-0.170932,0.216463,-0.0301366,0.155082,-0.383086,-0.102728,-0.209036,-0.0571094,0.0257559,0.0994063,-0.217945,0.111368,-0.227827,-0.134838,-0.242569,-0.013337,0.021965,-0.271533,-0.121208,-0.182733,0.0268155,0.124167,0.346154,0.115065,-0.120631,0.00952938,-0.372829,-0.267625,-0.0759568,-0.469197,-0.092278,0.242232,-0.172216,-0.0618158,-0.664314,0.164165,0.0954687,-0.116959,0.313733,0.0295612,-0.474344,0.0618356,-0.319485,-0.413824,-0.0150352,-0.0393658,0.128995,-0.101827,0.174382,0.0474056,0.144586,-0.392069,-0.168243,-0.0163768,0.169824,0.245134,-0.0834111,0.276236,0.12278,-0.174598,-0.124282,-0.0534029,-0.0418496,-0.131625,-0.112972,-0.120546,-0.258653,0.0252619,-0.163289,0.0297716,-0.0309457,0.0510066,-0.137037,-0.210345,-0.162758,-0.489765,-0.0413225,-0.060852,-0.172182,-0.0867055,-0.28312,0.126551,-0.0617213,0.17661,-0.517748,-0.0691664,0.0210655,-0.211715,-0.200242,0.0560963,0.0998782,0.415784,-0.112893,-0.0705841,-0.103232,0.29827,0.0214009,0.0977157,0.207569,-0.0161635,0.0942156,0.0289826,0.1638,-0.0477489,-0.00851553,0.00346127,0.111177,-0.418313,0.180865,0.292481,0.151353,-0.204973,-0.0190289,0.137896,0.281824,-0.175973,0.19839,0.297094,-0.00966248,-0.189358,0.0245757,0.152838,-0.251532,-0.501614,0.0340764,-0.10831,0.556835,0.0642739,-0.362964,-0.176738,0.0939587,-0.079535,-0.0321305,0.0579905,-0.255949,0.11409,0.0788458,-0.206867,0.186762,0.0458748,-0.345784,0.203789,0.0728188,0.633692,0.0877191,-0.473704,-0.0810021,-0.00692314,0.14708,0.113426,0.0894211,-0.0939944,-0.00167805,-0.253968,0.301258,0.0273715,0.0652859,0.0297184,-0.155142,0.108984,0.00432717,-0.0391965,0.0929251,0.146472,0.163505,0.416624,-0.260973,-0.0768476,0.0953507,-0.0440937,-0.108087,0.340665,-0.338853,0.131848,-0.241344,-0.0463016,-0.151926,0.0824705,0.194533,0.0826273,0.218702,-0.161798,-0.384798,0.00596569,-0.00792014,0.044317,-0.0302088,-0.203498,0.387494,0.345033,-0.0612478,0.157218,-0.256604,-0.0444331,-0.0563288,0.0415934,-0.274846,-0.211106,-0.263162,0.3298,0.103455,-0.177116,-0.112346,-0.116192,0.0835429,0.0296007,-0.274659,0.181586,0.107061,0.0970496,-0.295722,0.260006,0.158194,-0.13679,0.164218,-0.00482352,0.299059,-0.172499,-0.344566,-0.162049,0.394244,-0.172715,0.292735,0.442485,0.134727,-0.13469,0.286223,-0.365968,0.274859,0.311992,0.0194843,-0.410414,0.108882,0.272443,0.262607,-0.367064,-0.0889314,0.0794081,-0.113963,-0.211628,-0.347034,-0.00769071,0.374637,-0.0866174,0.00945468,0.0917622,-0.136951,0.148915,-0.358997,-0.0169307,0.347376,0.0256629,-0.0580723,-0.274907,-0.150745,-0.178475,0.0370791,0.177128,0.0906049,-0.166344,0.0541307,-0.21398,0.364536,-0.161113,0.146297,-0.0724604,-0.167336,0.199845,0.00976661,0.0926508,0.0101477,0.254686,0.0296937,-0.0304958,0.0611592,0.0387711,0.140955,-0.165341,0.00435423,-0.204037,-0.0437093,0.13687,0.18662,-0.147859,-0.0944279,-0.16648,0.262529,-0.0552962,0.136478,0.0445401,-0.18113,-0.232474,-0.15359,-0.308087,0.125301,0.378275,0.155224,0.0358123,-0.217365,0.240239,0.312127,0.0345481,-0.210098,0.0694735,-0.149939,0.049984,0.282239,0.190293,0.0990974,0.188603,0.161723,0.0847411,0.00374016,0.118505,0.0494833,0.230611,0.428198,0.0286997,-0.159951,-0.250138,0.296778,-0.0770025,-0.101367,0.180892,-0.346302,0.101754,0.0576357,-0.101314,0.104289,0.161277,0.221924,0.314611,-0.367114,0.147318,0.110946,0.101478,-0.080274,-0.401468,0.0436613,0.193363,0.0635669,-0.125084,0.0469384,-0.0676767,0.0802612,0.122181,0.22878,0.566732,-0.0514174,-0.110271,-0.421203,-0.0174315,-0.0142266,0.133764,-0.38723,-0.496706,0.133706,-0.0484241,0.126512,0.101021,-0.0411923,-0.0696088,0.278503,0.124661,0.0971002,-0.359761,0.014892,0.113949,-0.261027,-0.0312506,0.00959193,0.0990915,-0.262099,0.0240012,-0.340923,-0.295294,-0.0194186,-0.325993,0.272142,-0.0420153,0.150793,0.0693065,0.357037,0.283636,0.241936,-0.20606,-0.0432867,-0.131807,0.157669,0.260796,0.171958,0.316667,0.285857,0.16625,0.0408249,0.397953,0.221779,-0.630529,-0.270634,0.279606,0.0542885,0.242465,0.0157311,0.00498837,0.0703542,0.104447,0.40332,0.0430698,-0.125418,0.105111,0.295133,0.144981,0.176207,0.0033723,-0.128243,-0.396699,-0.0722027,0.110026,-0.0573769,0.0937833,-0.107713,0.282226,-0.457318,0.0846667,0.0414236,-0.239664,0.121383,0.0665616,0.000295565,0.18311,0.00911134,-0.120412,0.0717845,0.0900123,0.0827732,0.0538929,-0.183687,0.385756,-0.37976,0.558364,0.135119,0.163746,0.0396474,-0.150902,-0.260502,0.294559,-0.0948469,-0.00817514,0.000799273,-0.87892,-0.220385,-0.346016,0.140465,0.161138,0.0703641,0.149327,-0.313148,-0.10858,-0.130771,-0.305052,-0.161031,-0.113138,-0.196943,-0.137006,0.031708,0.230576,0.0574177,-0.0413916,-0.167193,0.249158,-0.059575,-0.092646,-0.226215,-0.182771,-0.305212,0.110111,0.035971,0.0423916,-0.0386536,-0.296618,-0.116496,-0.177236,-0.427871,0.203962,0.0654587,-0.0547439,-0.154674,0.397951,-0.160955,-0.0075083,-0.152571,-0.09836,0.0755797,0.267994,-0.160885,0.284992,0.199423,-0.151388,-0.229152,-0.143209,0.12258,0.0927436,0.137578,0.406081,-0.0116779,-0.236374,-0.194983,0.0471583,0.152288,0.301969,-0.262005,0.0470045,0.289298,-0.3662,-0.023998,0.229185,-0.0864606,-0.291287,-0.00166765,0.179141,-0.0816318,-0.0460097,0.0908542,-0.219148,0.368267,0.32387,-0.374988,0.236242,0.0525261,-0.132624,-0.511993,-0.215191,-0.0190571,-0.336518,0.13801,-0.203688,0.341781,0.171786,-0.168092,0.308413,-0.109407,-0.167181,0.0990459,0.171297,-0.0229509,0.0761261,-0.132777,0.391183,-0.075697,-0.314236,0.127233,0.20203,-0.348485,-0.438759,-0.00291619,-0.200141,-0.0468178,0.403796,-0.0238284,-0.159963,0.0669186,-0.189968,0.241898,0.0773974,0.258309,-0.212818,-0.137164,0.0145405,0.0611941,-0.103869,0.089502,-0.0952337,0.1099,0.00839634,-0.235961,0.159967,0.115645,-0.28184,0.124668,-0.13688,-0.0900653,-0.0939398,0.0984095,0.198277,0.11193,0.237484,0.263983,0.124464,-0.0933155,0.143538,-0.22036,-0.292412,0.0289039,-0.211072,-0.198711,-0.534153,-0.0292197,-0.17055,-0.256611,-0.05831,-0.106381,0.134336,-0.190036,-0.148949,0.135077,0.130742,0.0457813,-0.576028,0.00621258,-0.419114,0.0133794,-0.0554159,0.0547583,0.0504825,-0.0197649,0.230606,0.0849435,-0.119858,-0.0715389,0.0714574,0.215338,0.395229,0.00372683,0.319933,0.00506433,-0.031714,0.238245,0.151813,0.203559,-0.185088,0.0522952,0.151364,-0.124357,-0.244501,-0.118415,-0.182667,-0.322059,-0.160316,0.271786,0.0647135,0.161467,-0.0809664,0.154754,0.103294,-0.0822275,0.517491,0.013224,0.244353,0.000385385,0.163026,0.0334395,0.0107523,-0.311773,-0.173261,0.49573,-0.10672,0.0141706,-0.30062,0.139836,-0.206019,0.187622,-0.205834,0.105763,-0.111109,-0.141264,0.388885,-0.145635,-0.00639826,-0.355533,0.00506047,0.293777,-0.248024,-0.62132,0.171621,-0.164585,0.0926243,-0.0296591,0.141449,0.243196,0.0501118,0.0791219,0.271744,-0.0254719,-0.257106,0.120255,-0.0170307,-0.163363,-0.00695394,-0.365615,-0.173822,-0.0646261,0.128665,-0.221299,0.0852899,0.0543917,0.0913671,0.338285,0.0514477,0.110876,0.00214925,-0.36767,0.0746724,-0.0507806,0.286987,0.0851143,0.172688,0.0403564,-0.364829,0.0891227,-0.38842,0.445061,0.0382695,-0.16616,0.250621,-0.0155406,0.0512845,0.0327987,-0.52829,-0.0718741,0.0626512,-0.0794518,0.0601256,0.32407,0.139794,0.113972,0.334568,0.0320128,0.381105,-0.0848108,-0.150854,0.107901,0.170253,0.0799795,0.0468225,0.0437816,0.163417,-0.175324,0.186607,0.174492,-0.0588375,0.47635,0.168929,0.291355,0.0960932,0.134915,0.192254,0.0338167,0.000124447,0.36525,0.115616,0.0128106,0.0739962,0.32509,-0.268452,0.0691854,0.0672497,-0.152385,-0.252479,-0.0704205,-0.0963354,-0.324288,-0.0458135,0.0204915,-0.219641,-0.0791665,-0.133646,0.306342,0.0237747,-0.0918762,0.226354,-0.155523,0.467392,-0.0838319,-0.128651,0.0288752,0.0715514,-0.0973427,0.0681039,0.282061,0.0451114,-0.209059,-0.143215,0.214257,-0.315647,0.536787,0.163723,0.0791837,-0.105473,0.0966923,0.237724,-0.188797,-0.200133,-0.223747,-0.0578177,-0.0131843,-0.247443,0.203021,-0.168958,-0.298846,0.253477,0.280237,-0.205846,0.178652,0.324709,-0.0969214,0.311136,-0.0812358,0.0670406,-0.2299,-0.104985,-0.100399,-0.358292,-0.0120314,0.151608,0.107332,0.0763753,0.157233,0.181192,0.330185,-0.0268293,-0.310848,0.0970831,0.0669964,0.206143,-0.0328985,-0.0381455,-0.234921,0.148146,-0.224835,-0.328495,0.0164397,0.211891,0.00592415,0.0352901,-0.0176106,0.293598,-0.182827,0.0704597,0.0697877,0.0947301,0.267808,0.08775,0.250536,0.237076,-0.171235,-0.200324,-0.22871,-0.237672,0.146126,0.494861,-0.307942,0.233662,0.19489,0.157604,0.166409,0.0590481,0.184755,0.19757,-0.218215,0.0577672,0.117807,-0.0735056,-0.177283,0.23036,-0.0267932,0.11532,0.0377643,0.0505062,0.241599,-0.0928156,-0.0885982,0.0364013,0.186541,-0.363389,-0.0716874,0.151641,-0.348517,0.0379472,-0.251708,-0.0490797,0.302263,-0.127171,-0.131571,-0.405221,0.0124008,-0.655717,0.00695131,0.213797,-0.0806023,0.327152,-0.157425,0.174994,0.281387,0.248603,-0.081214,-0.0484206,0.217591,-0.167805,-0.19503,0.0550267,-0.191188,0.152169,0.0195942,0.171156,0.0207417,0.193244,0.072974,-0.414953,0.199968,0.015471,-0.125222,0.0724962,0.0223002,-0.356179,0.299123,0.0956292,-0.215137,-0.242405,0.0389323,-0.0544226,0.0912934,-0.0463106,-0.0328937,-0.355646,0.210193,0.0210409,-0.132981,0.0267127,0.0458026,-0.110095,0.174369,0.29696,0.441334,-0.31801,-0.141484,0.0687602,-0.138706,0.228441,-0.0815449,-0.243386,-0.0721609,-0.106337,-0.0311935,-0.0936809,0.127212,-0.0929267,-0.0186535,0.0354691,-0.110355,0.19626,-0.056666,0.0701374,-0.239508,-0.0681038,0.352944,0.0732081,-0.12952,0.168485,0.391899,-0.134808,-0.176793,0.277407,0.263678,-0.27417,0.349808,0.197007,-0.089103,0.16537,-0.066996,-0.0284414,0.268026,-0.309378,0.0475392,-0.0701685,-0.40915,-0.0457942,0.0169606,0.35845,0.0179937,0.0290418,0.0890521,0.11504,-0.0276689,-0.171619,0.23931,-0.219608,0.349479,-0.126005,-0.371992,-0.0572328,-0.184221,0.393528,-0.200577,-0.15449,0.284878,0.0371771,0.113835,0.187901,0.195688,0.154886,-0.112485,0.0617958,0.223086,-0.0492424,-0.248296,0.245531,0.207188,0.241493,0.0858108,0.165292,0.231296,0.136967,0.120834,-0.168093,-0.0935019,-0.139543,0.151883,0.151945,0.0727766,0.0278126,0.0895198,0.0508233,0.070299,0.0664251,0.269829,0.323007,-0.226476,-0.117824,-0.104569,-0.177952,0.0267108,-0.226139,-0.306976,-0.0401323,0.0442024,0.216153,-0.163806,0.111764,-0.037067,0.118298,-0.0570237,0.118425,0.336384,0.107701,0.318113,-0.120243,0.111248,0.0549329,0.0419836,-0.060626,-0.125144,0.203623,0.0104553,-0.108217,-0.0722691,-0.225044,0.256106,-0.320077,-0.316867,-0.251566,0.0879695,0.0998093,0.198596,0.0581342,0.421874,0.135877,0.336462,-0.143183,-0.0746373,-0.198165,-0.31797,0.16036,0.133116,0.14615,-0.0281941,0.0519915,-0.0772152,0.145744,-0.0583435,-0.115873,-0.308955,-0.0620882,0.240472,-0.085517,-0.198444,0.0115876,0.201474,-0.12563,-0.21433,-0.278401,-0.506298,-0.100479,0.205793,0.00423588,0.131235,-0.0101949,-0.409824,0.187521,0.174057,0.0670165,-0.268234,0.0307733,-0.0138849,0.293819,-0.240954,-0.267056,-0.218473,0.0300247,-0.124625,-0.456782,-0.0632248,0.0383293,-0.0500971,-0.00271904,-0.155391,-0.0838735,0.151172,0.359381,-0.0812103,-0.0323043,-0.15536,0.196826,-0.27293,0.238171,-0.0530803,0.292325,0.0656263,-0.156196,-0.133812,0.157916,-0.139745,-0.182908,-0.142008,-0.0651904,0.118953,-0.207525,-0.416288,-0.119842,-0.174124,0.112276,-0.0594684,-0.0395585,-0.281779,-0.139652,0.273234,0.342668,0.0257553,-0.143984,-0.20049,0.179336,0.207559,-0.138535,-0.345209,0.271355,0.289366,-0.133472,0.0735652,0.276777,0.156417,0.0827648,0.123396,0.160746,0.102933,-0.088663,0.173222,-0.478489,-0.00624201,0.200833,-0.0377097,0.12104,0.0399466,0.494014,-0.053782,0.0680174,0.205338,-0.227352,0.000100402,0.212812,-0.140887,0.262507,-0.21009,-0.230873,-0.310881,-0.0650355,0.341981,-0.37202,0.0547361,-0.0227873,-0.0846322,0.0434814,-0.175643,0.378362,-0.525794,-0.230836,0.192188,0.128642,0.237878,0.0639115,-0.282606,-0.117194,0.340202,-0.160856,0.104727,-0.0335477,0.039943,0.0232883,0.105972,-0.00107007,0.16061,-0.10117,0.00803243,0.168425,-0.327759,0.00563204,0.245418,-0.268245,0.0506887,0.0592008,-0.0671414,0.0200269,-0.199009,-0.253493,0.107445,0.00626491,0.02593,0.149489,-0.103285,-0.0878473,-0.121011,-0.146916,-0.115492,0.247728,0.0919945,-0.281791,0.140997,0.0610895,0.107662,0.399696,0.427302,-0.0943645,0.0737215,-0.376197,-0.205622,-0.171965,-0.290847,0.125282,-0.073492,-0.0875862,-0.0468414,0.3543,0.0352702,-0.274998,0.105414,-0.0833703,-0.333916,-0.213621,0.293504,-0.176399,-0.278888,0.044862,0.408946,0.034976,0.0882757,0.236203,0.240681,0.195819,0.293371,-0.0235617,0.148601,0.0749789,-0.0295399,0.281721,0.0589185,-0.0361427,-0.07461,0.236031,-0.177778,-0.354664,-0.0740564,0.330271,0.0264691,-0.132618,-0.341518,0.427176,0.0122998,-0.467276,0.300159,0.103637,0.368808,-0.28226,-0.173947,-0.744002,-0.190649,-0.271172,0.00344026,0.20027,-0.2191,-0.0451069,-0.294594,0.0958825,0.0956456,-0.479483,0.578939,0.0567934,-0.0131393,-0.310302,-0.0341854,-0.0721965,0.125978,-0.0450819,-0.11931,0.486279,0.116348,-0.060786,0.149339,-0.171336,0.041219,-0.10192,0.102222,-0.0273962,-0.113071,0.180418,0.0612608,-0.150105,-0.0783013,0.0330449,-0.0894462,0.00834627,0.405307,-0.0912584,-0.136214,0.341747,0.326402,0.188219,-0.252354,0.296684,0.0408111,-0.188941,0.334729,0.235952,-0.252559,-0.264422,0.104871,-0.00368513,0.351237,-0.16548,0.460818,0.141445,-0.0201575,0.456365,-0.361042,-0.113677,0.0151745,0.0691367,-0.105495,0.115192,-0.111377,0.0418841,-0.0548043,0.544023,0.171502,0.106627,0.0252304,-0.0906556,0.303561,-0.104894,0.362371,-0.333047,-0.0376481,-0.236958,-0.0872344,0.103559,0.437655,0.192504,0.0726002,0.198011,0.232833,-0.188197,-0.0592281,0.221652,0.0505199,0.12822,-0.389078,-0.0545316,-0.294611,-0.32903,-0.407532,0.37246,-0.287101,-0.0717075,0.108986,-0.0778319,0.22245,0.446366,-0.148757,-0.442256,0.04646,0.373115,0.210647,0.273584,0.174299,-0.144808,-0.173049,-0.109995,0.346406,-0.0970029,0.135797,0.116451,-0.0183962,0.315635,-0.188029,-0.203934,0.179873,-0.0691923,-0.210132,0.246538,-0.308452,-0.163637,-0.557436,-0.166347,-0.368377,-0.244128,-0.0856448,-0.142295,0.0549274,0.136816,-0.0565812,0.0688071,0.111864,-0.286179,-0.33128,0.217411,0.0853125,0.125341,0.223545,0.00895946,0.265819,0.539986,0.367091,-0.0939644,-0.240336,-0.119598,0.065851,-0.217367,-0.090443,0.0747178,-0.06127,0.152988,0.0935002,0.140147,0.049835,0.457038,-0.149733,0.0338974,-0.189254,0.145405,-0.181436,-0.0882459,-0.1993,0.0640944,-0.103861,-0.421481,-0.373161,-0.0738694,-0.0798004,-0.272853,-0.00868655,-0.0529841,-0.476213,0.0207849,0.54947,0.299905,0.231786,-0.0122448,0.00686648,0.106616,0.276364,0.314138,-0.327059,0.26645,0.114536,-0.276965,0.156964,-0.191836,0.0925321,-0.0471981,-0.199734,0.148096,0.297605,0.0238723,0.0189888,0.239725,0.33603,-0.260069,0.40762,-0.291036,-0.120458,-0.119703,-0.136249,-0.164574,0.0212526,0.0813188,0.017029,0.0670629,-0.482818,0.355157,0.201675,-0.116731,-0.47547,0.0596808,-0.325402,0.0468873,0.283371,0.017973,-0.232861,-0.181073,0.03567,0.121504,-0.0626159,-0.0484439,-0.27194,-0.0769837,-0.0345899,0.0135355,-0.281128,0.03688,0.157798,-0.168164,0.0576725,0.160882,0.26967,-0.265081,0.236161,0.0892291,-0.218978,0.0856778,-0.254612,-0.278395,-0.211326,-0.253322,0.295374,0.0123983,-0.00458384,0.0429919,-0.0692524,0.0203439,0.0286302,-0.281089,0.109653,0.150413,0.0388303,-0.268098,0.115484,0.0874318,0.222766,-0.218728,-0.265642,0.104755,0.170845,-0.0155197,0.276981,-0.0193154,-0.306825,-0.0638744,-0.0870509,-0.0363243,-0.0709682,-0.104109,0.264543,0.224117,-0.102348,-0.293434,0.0565754,0.379913,-0.035024,-0.227719,0.100033,0.244663,0.0257467,0.0887772,-0.0253354,0.0845073,-0.184404,0.107402,-0.0695976,0.42671,0.221851,-0.384396,0.419484,-0.248587,-0.38065,-0.0125444,0.223954,-0.0642436,0.052133,0.0399328,0.0473749,-0.0924308,0.142681,0.348372,0.0886155,0.371495,0.224862,-0.263393,0.560671,-0.102412,0.248143,-0.124213,0.32656,0.19058,-0.0331726,0.339939,0.38026,0.200548,0.00700669,0.0857677,-0.163948,-0.285343,-0.196477,-0.33092,-0.0655965,0.223945,0.274452,0.39087,0.0145388,0.0688349,0.0398213,0.244646,-0.127316,-0.336115,-0.147585,-0.0661952,-0.218368,-0.103155,0.0405106,0.126956,0.273826,0.249864,-0.380509,-0.0807375,-0.256419,0.0843229,0.374843,0.500395,-0.222195,0.0723586,0.102009,0.124162,-0.0671708,0.348246,0.104329,0.182227,-0.230728,-0.257647,0.137392,0.191295,-0.02503,0.208395,0.0220181,0.196566,-0.258506,0.011862,0.0376772,-0.0797629,-0.219631,0.337507,-0.528149,0.132894,-0.00961496,-0.0761533,-0.200739,-0.430406,0.0838707,0.0848739,0.0774547,0.168498,0.155947,0.264875,0.204176,0.00587054,0.0616941,0.183807,-0.266725,0.0157285,0.0955986,0.05819,0.259471,-0.398528,0.0627855,0.182226,0.331773,0.280015,-0.0140477,-0.141521,-0.168287,-0.27285,-0.0379065,-0.0690297,0.221643,0.48059,0.200159,0.187267,0.246982,-0.0400418,-0.42167,-0.207836,-0.140167,0.286096,-0.0453003,-0.146142,-0.132748,0.180566,0.0274781,-0.184695,0.248932,-0.213739,0.129138,0.201247,0.00967601,-0.230413,-0.127356,-0.206386,0.0430612,0.188107,-0.139934,0.340403,0.0862808,0.26604,0.530762,-0.0127354,0.0722238,0.086638,0.312715,-0.142221,-0.17966,0.319441,-0.150415,0.0952441,0.136,0.307737,-0.127323,-0.355094,0.185825,-0.381332,-0.379701,0.443487,0.171521,0.129428,-0.0968049,0.0314161,0.0973218,-0.266773,-0.299937,0.0667837,-0.415692,0.44435,0.150941,0.130839,-0.0237337,0.0632195,0.136532,0.0150245,0.297612,0.192684,0.0451175,0.199279,0.0490078,-0.166943,-0.330852,-0.0107862,-0.241911,-0.220676,-0.138355,-0.246719,0.236004,0.238159,0.260433,-0.25073,0.00331948,0.130891,-0.0663332,0.219602,-0.193139,0.0081317,0.065153,0.320074,0.166436,0.501163,0.373621,0.274432,-0.157385,0.187355,0.144302,-0.0247702,0.227902,0.279138,0.070281,0.0814279,0.0666641,-0.158947,0.132533,-0.125178,-0.191115,-0.0732462,0.220753,0.324372,0.081235,-0.00629175,0.0268994,-0.332259,0.182842,0.41012,0.164712,-0.117935,0.124906,-0.149493,-0.35773,0.351821,0.174678,-0.2205,-0.0778534,0.301814,0.491171,0.0270389,0.222512,0.0813367,0.364728,0.315407,-0.267397,0.570162,-0.129459,-0.000311459,0.205385,0.101555,0.546674,-0.251536,-0.024426,-0.0415733,0.117248,0.100435,0.0557541,0.147876,-0.0370721,0.283311,-0.217199,0.150249,0.01637,0.0409728,0.054181,-0.190446,0.106754,-0.0312942,-0.246946,-0.0905519,0.403733,0.155806,-0.0373955,0.0623435,-0.105242,0.202087,0.115396,-0.318747,-0.0727614,0.159905,-0.122125,0.131477,-0.05898,0.294035,-0.183172,0.194466,-0.0221882,-0.0202656,0.119361,-0.0335517,-0.0356275,0.0631502,0.286577,0.138764,0.0796256,-0.0934747,0.0717993,-0.165497,0.174925,-0.201769,0.33871,-0.128896,-0.157666,-0.043388,0.290834,0.18589,0.0647783,-0.216746,0.0135572,-0.00795538,-0.299892,0.304659,0.520313,-0.197894,0.343957,0.25662,-0.0852958,0.220215,0.157886,-0.0682689,0.0720986,-0.230107,0.180257,-0.0200974,-0.124607,-0.106436,-0.0821062,0.177352,0.292865,-0.0329237,-0.0310595,-0.0801598,-0.485938,0.171642,-0.0163981,-0.0640528,0.320535,-0.11205,0.00429809,0.029139,0.422978,0.129293,-0.35958,0.107451,0.363749,-0.0168781,-0.0594638,0.316079,-0.36447,-0.192026,0.233308,0.299306,0.251941,0.193752,-0.185517,-0.0186717,0.310352,0.0691762,0.0759806,0.373941,0.0463634,-0.229524,0.520875,0.182613,-0.124518,-0.455477,-0.102148,-0.275545,0.0961339,-0.106619,-0.176737,-0.0187092,-0.0629593,-0.295321,0.178671,-0.0794733,-0.188131,0.177837,-0.266811,-0.045459,-0.349714,0.246334,-0.16459,-0.263914,-0.227039,-0.0414826,-0.0576534,-0.23795,0.035262,-0.189846,-0.177352,0.124501,0.0646354,-0.00853025,0.511719,-0.0991283,-0.0607142,-0.145518,-0.149744,-0.157972,-0.285841,-0.0397687,-0.240849,-0.194712,0.0562163,-0.0248091,0.0785359,0.0465551,-0.317565,-0.0404243,-0.148329,-0.252499,-0.270326,0.0386271,0.0158803,-0.0886299,0.144695,-0.485465,0.00148222,-0.0862437,0.216232,0.293242,0.121109,-0.10139,-0.332327,-0.257262,0.238577,-0.125268,0.232324,0.191992,-0.159015,-0.0948941,-0.284198,0.346588,-0.101904,-0.0270245,-0.40667,0.0795943,0.0664785,-0.00794802,0.0164777,-0.232422,0.143645,-0.0922399,-0.0884039,-0.11692,-0.0490983,0.154286,-0.0677904,0.167018,0.238816,-0.112562,0.165651,-0.173609,-0.341244,0.0620436,-0.185371,0.25271,-0.231839,0.107197,-0.00103787,0.0811959,0.125224,-0.270811,0.346378,-0.0138488,-0.23439,-0.287903,0.250342,-0.0155844,-0.235906,0.0536764,0.211634,0.0503729,-0.115586,-0.00304328,0.218056,0.182785,0.18109,-0.322079,-0.113868,-0.0312835,0.54149,-0.19796,0.0635649,0.314084,-0.0960026,0.177896,0.118357,0.0365682,-0.220099,-0.49644,0.35623,-0.0892545,0.164742,0.250588,0.0013958,0.169816,-0.181553,-0.074158,-0.0468822,0.0982139,-0.0826629,-0.0297065,0.0077482,0.072708,0.064823,0.0998127,-0.0753314,0.186435,-0.137232,0.183632,-0.13643,0.09896,-0.501491,0.33128,-0.105615,0.21788,0.324646,0.179169,-0.256876,-0.141641,-0.192658,0.0434116,-0.40208,0.292524,0.167703,-0.0414211,0.0516817,-0.467209,-0.205837,0.0262736,-0.203316,0.165207,-0.046066,0.0152408,0.310544,0.0507024,-0.0449881,0.0138192,-0.052719,-0.274468,-0.0762398,0.0789914,0.30826,0.0568521,0.00612178,-0.0529661,-0.0541334,-0.320886,0.00249736,-0.330433,0.297254,0.0836568,-0.0816644,0.109195,0.336622,-0.000206851,-0.109047,0.300946,-0.409465,-0.240803,0.0559694,-0.194767,-0.0930097,-0.0912283,0.0603697,-0.156765,0.0260126,0.102509,0.106923,-0.22103,-0.322485,-0.266737,0.209244,-0.184866,-0.153355,0.176277,-0.0650388,-0.17803,-0.366446,0.286126,-0.00774819,-0.282052,0.106711,-0.210455,0.111747,-0.18818,0.541678,-0.189267,0.179682,-0.574024,-0.269367,0.0737552,0.0812432,-0.30056,-0.0595876,0.215657,-0.165093,-0.050826,0.164209,-0.301787,0.0738284,-0.0104051,-0.109614,-0.198096,0.330955,-0.102338,0.0659716,0.167924,0.139088,0.106634,0.295014,0.084549,-0.237999,0.0308483,0.322341,0.325851,-0.0646605,0.0224729,-0.00520697,-0.128215,0.230567,0.152877,-0.146922,0.248552,-0.222092,0.293823,0.200118,0.0510392,-0.282928,-0.0279853,0.0519749,0.39109,-0.157453,0.500546,0.102205,-0.198488,0.351436,0.0940214,-0.306879,-0.0168141,-0.203937,-0.13406,-0.0294456,-0.180146,-0.32793,0.498592,-0.155165,0.200217,0.0568331,-0.340197,0.106171,-0.311416,0.415192,0.123812,-0.241822,-0.153493,-0.0905031,-0.266799,-0.277394,0.0325672,0.0300027,-0.334257,-0.205427,-0.43422,0.0286944,-0.261048,0.407529,0.0827585,-0.319965,0.123294,0.359241,0.33166,-0.018546,0.250022,-0.138801,-0.321786,-0.0325261,0.185934,-0.0503693,-0.233197,-0.0636382,-0.101909,-0.125337,-0.130777,-0.0220523,0.0760554,-0.0767863,0.122427,0.156037,0.0196093,-0.235978,0.213473,0.0642908,-0.128689,-0.157905,0.314884,0.0695105,0.000304457,0.0725671,-0.147671,0.283292,0.412882,0.0158804,0.0787162,-0.100811,-0.226963,-0.0357337,-0.473602,0.114134,0.304855,-0.142471,-0.340311,-0.334784,0.220282,0.454885,0.102169,-0.00727054,-0.181362,0.0739105,-0.180487,0.229096,0.00362439,0.0351609,0.321369,0.0966069,0.00726845,0.159879,0.200431,0.252274,-0.304008,-0.0640757,-0.122156,0.0810978,-0.285257,0.270626,0.0296313,0.106138,-0.0647793,0.302805,0.283263,0.0330137,0.228446,0.182174,-0.233392,-0.213106,-0.328117,0.146425,-0.173395,-0.253176,0.00889772,0.175175,0.00974338,-0.242751,0.0782641,0.0643327,0.226784,0.0566876,-0.0572316,0.0119974,-0.319537,0.244322,-0.0252262,-0.0354069,0.323123,0.0931585,0.02547,-0.0561306,0.0811592,-0.0944766,0.24911,-0.0951295,0.114661,-0.450665,0.598466,0.126326,-0.156898,-0.0903776,0.0783126,-0.123054,-0.0353707,-0.206821,-0.0578264,-0.259931,0.0518085,0.100983,-0.284238,0.0466459,0.118793,-0.401957,0.0940028,0.00104156,-0.391712,-0.34708,0.045728,0.00713301,-0.190565,0.0364219,-0.1387,0.0303359,-0.439128,0.340977,0.0644659,-0.271172,-0.0874378,0.150699,0.227956,0.183019,-0.00445547,0.00540853,0.685313,-0.0368694,0.13202,0.0890276,0.104573,-0.0470548,0.131258,0.174896,-0.195286,0.216765,0.304023,0.0596381,0.076357,0.141506,-0.173572,0.0200158,0.0674608,-0.0109403,0.356896,-0.165856,-0.277644,-0.163427,0.133911,-0.324731,0.240663,0.217714,-0.0263992,-0.555517,-0.29343,-0.317033,0.138409,0.0397808,-0.0368728,0.218242,0.151775,0.458207,-0.206629,0.0235503,-0.247863,0.114294,-0.0857637,0.205072,0.415976,0.0593428,0.12247,0.137079,-0.080518,-0.109997,-0.21625,0.0562373,-0.246921,0.202708,-0.0793472,-0.354383,-0.162981,-0.166739,-0.00612741,-0.195465,-0.0942532,0.327264,-0.245371,0.15413,-0.0628344,-0.205058,0.112084,-0.135038,-0.270141,0.0299023,-0.00256339,-0.255471,0.51985,0.0713149,0.0495851,0.00619035,0.0230465,-0.127233,0.0277597,0.042604,-0.397189,0.197711,-0.0295489,0.33728,-0.150454,0.195152,0.170114,-0.283984,0.282449,-0.377383,-0.0995873,0.0468986,-0.0686941,-0.0566535,0.135556,-0.121844,-0.408033,0.164886,0.173288,-0.320991,0.00923635,-0.0375453,0.0915218,-0.236849,-0.337789,-0.0600804,0.063868,-0.199632,-0.18701,-0.0874119,0.110936,0.0584822,0.214393,0.117331,-0.338954,-0.564489,0.432869,0.252229,0.0662975,0.48643,0.198924,-0.0188901,0.119019,-0.125974,0.344295,-0.0262948,0.151131,-0.0367021,-0.288661,-0.0394696,-0.0188147,-0.379633,-0.0534075,-0.186982,-0.0118613,-0.00257149,0.0792675,-0.348822,0.0188314,0.163384,-0.0741717,-0.405055,0.262998,0.274976,-0.0851247,0.0917778,-0.320339,0.14978,-0.11856,-0.266293,-0.070784,-0.436526,-0.0962034,-0.0558898,-0.22214,-0.559144,-0.026699,-0.311728,0.0228678,-0.108537,-0.0818745,0.00954918,0.418055,0.178887,-0.00771774,-0.333901,0.40445,-0.234441,-0.144444,-0.040507,-0.155712,0.281957,0.272535,-0.425094,-0.0353651,-0.0849341,-0.137445,-0.254161,0.0678407,-0.204102,0.272591,0.201168,0.231599,0.280058,0.150902,0.084898,-0.185822,-0.0731742,0.117745,-0.0240933,0.265492,-0.230016,-0.0108695,-0.0198582,0.0831106,0.269649,0.18624,0.0203918,0.118723,-0.0204444,0.0317866,0.112671,0.0468176,-0.409292,0.146831,0.0511349,0.17851,0.118559,0.158912,-0.110819,0.13611,0.0134706,0.61835,-0.125037,-0.151161,0.110074,0.0410301,-0.184418,-0.582565,-0.189016,0.182384,-0.332054,0.287719,-0.0723464,0.11841,-0.0904536,0.206223,-0.206422,-0.0566923,-0.273328,-0.155896,-0.1541,0.138645,-0.214354,-0.194871,-0.0542879,-0.441014,0.178809,0.0924303,0.0141031,-0.106862,-0.195268,-0.060944,0.101342,-0.31334,-0.151009,0.160388,0.144776,0.138593,-0.0424748,-0.20257,-0.127516,-0.488978,-0.056916,-0.334416,-0.315035,0.149755,0.0810902,-0.19711,-0.0202384,-0.00785274,0.38658,0.196297,-0.00403835,-0.273509,0.062685,-0.118351,0.15866,-0.0119255,-0.228157,0.0230842,0.412755,-0.0732666,-0.140501,-0.167083,0.118204,-0.0737074,0.168127,-0.175696,0.00639678,-0.0117664,0.000885435,-0.176286,0.335629,0.116787,0.418807,0.127901,0.0120241,0.131288,-0.0202502,0.0950814,-0.0130791,0.30323,0.0499505,0.331982,0.0941845,-0.0574784,0.321798,0.170409,0.243188,0.106355,-0.0792367,0.251116,-0.633853,0.183826,-0.0931508,-0.358394,-0.154565,0.0474112,-0.027507,0.240228,-0.0760853,-0.279956,0.411985,-0.381992,0.043588,0.0376121,-0.188203,-0.384584,-0.0501546,0.21457,0.178872,-0.20767,-0.17698,-0.0222385,0.136156,-0.317358,-0.246183,0.0679101,-0.170744,-0.396722,0.347354,-0.125061,-0.203143,0.32235,0.167858,-0.0213491,-0.032915,-0.18067,-0.253136,-0.035974,-0.167293,-0.00255067,0.268027,0.0986487,-0.141972,-0.422175,0.155949,-0.331724,0.0884242,-0.463328,-0.172933,0.0226433,0.012652,0.154446,-0.393734,-0.14937,-0.366968,-0.0968367,-0.198439,-0.0404439,0.217211,0.10737,-0.123463,0.250973,0.158694,-0.0377195,-0.0208999,0.0366381,0.372741,0.286441,0.114599,-0.160195,0.490404,-0.299509,-0.0588911,0.0926117,-0.112522,-0.330008,-0.051958,0.433486,-0.0694871,0.213595,0.132062,-0.0321919,-0.163039,-0.323031,0.13775,-0.016524,-0.105993,-0.156122,-0.223015,0.0875942,-0.070244,0.161526,0.130987,-0.123601,-0.118412,0.231228,-0.229663,0.0291201,0.249437,0.310221,0.155143,-0.153751,0.470922,0.198415,0.101185,0.226713,0.0130557,-0.487558,0.0218243,0.0232701,-0.229535,-0.166442,0.0995989,-0.309129,0.230352,-0.154596,-0.367192,-0.0579452,0.509242,0.0540707,-0.0204478,0.188333,0.0958538,-0.281581,0.152627,-0.0110258,-0.0705751,0.0984282,0.130348,0.321078,0.424766,-0.0943979,-0.465048,-0.0328829,-0.151704,-0.10137,0.142188,-0.120074,-0.229008,0.0224273,-0.384468,-0.202633,0.0186811,-0.271087,-0.546492,0.0229734,-0.234046,0.2478,0.273509,-0.0907362,-0.216846,-0.369284,-0.079203,-0.1228,0.068063,-0.246257,-0.0505622,-0.243187,0.0421418,0.243693,0.0241845,-0.167137,0.248567,-0.436359,0.0520808,0.14075,-0.150743,-0.0367918,-0.0573733,-0.0281186,-0.661821,-0.0927732,-0.254119,-0.242086,0.0226645,0.0416947,0.222334,-0.00366868,0.0161476,0.0627247,-0.326205,-0.157268,0.270312,0.159397,-0.274287,-0.0965986,-0.151651,-0.0417507,0.0622014,-0.131934,0.277137,0.048464,-0.0835357,-0.0867139,-0.0767122,0.0892006,0.211286,0.312178,-0.30276,0.102739,0.270335,0.212918,0.0410686,-0.049792,-0.32036,-0.0910998,0.132574,0.370916,0.113732,0.0999162,0.118317,-0.0380084,-0.579656,0.0830218,0.18937,0.352301,0.285862,0.0398411,0.109671,-0.161738,0.0355015,-0.103699,-0.0138662,-0.318661,-0.420492,-0.0131132,-0.273412,-0.19188,0.124245,0.211378,-0.0869987,0.171052,-0.261783,0.219779,-0.223488,0.264165,0.0997014,-0.385342,-0.0581368,0.0019611,-0.148753,0.101829,-0.0636338,-0.249318,0.163959,0.41424,0.138041,0.179648,-0.18671,0.217748,0.262603,-0.391723,-0.121507,-0.0615872,0.0644927,0.0402317,0.0285335,-0.244927,0.014375,-0.363373,0.117127,0.113938,0.0185133,0.0151782,0.143239,0.0266182,-0.216317,-0.146336,0.240735,0.151371,-0.0254922,0.235337,-0.37481,0.287257,-0.264311,-0.107895,0.0816828,-0.19821,0.318359,0.108699,-0.321961,0.450647,0.234892,-0.212704,-0.163708,-0.42734,-0.0461182,0.0583528,-0.0126236,-0.0120685,-0.0045911,-0.224952,-0.0571585,0.18601,0.22679,0.013504,0.0392104,0.122136,-0.149954,-0.0158261,0.357437,0.0108173,-0.0934722,-0.167565,-0.30452,-0.230344,0.205162,0.163088,0.176231,0.0152195,0.111264,0.211542,-0.0391633,-0.181981,-0.45593,-0.167716,-0.0485246,-0.270975,-0.0160166,-0.188002,-0.0419607,-0.444226,-0.122784,-0.228413,-0.0886315,-0.0256093,0.0132758,-0.065039,-0.0945464,-0.120513,-0.238917,-0.176793,0.0494582,-0.0527783,-0.455765,0.220506,-0.017085,0.0784362,-0.130011,-0.306841,0.0727882,-0.31038,-0.0992344,-0.0780661,0.108911,0.332447,-0.122966,-0.365288,0.248663,-0.21496,0.147778,0.293817,-0.342099,0.065746,-0.0668802,-0.0283907,-0.230308,-0.0554848,-0.556002,0.187398,-0.177522,-0.0764267,-0.189281,0.02448,-0.263482,0.199802,0.408932,-0.151484,-0.297707,0.258142,-0.407533,0.11514,-0.319803,0.13293,0.0553778,-0.150224,0.0807637,0.0252375,-0.169533,0.123813,0.103602,0.327461,0.0705817,-0.378537,-0.175216,-0.372256,0.314247,-0.28592,0.00984277,0.177353,0.388233,-0.218205,0.101737,-0.309198,-0.0679766,-0.35929,0.304975,-0.029934,0.16636,-0.0869473,0.378065,0.0594128,0.341115,0.217315,-0.0183011,-0.148124,0.132313,0.0363023,0.410748,0.413384,-0.266807,0.0585293,-0.101466,0.463617,-0.336979,-0.0481106,-0.23342,-0.0184654,0.0893442,-0.330212,0.375327,0.00900054,0.264788,-0.132582,-0.272118,0.00378522,-0.0738956,0.196938,-0.160945,0.0726348,-0.113413,0.178964,-0.0382083,0.25928,0.13129,-0.263144,0.0576124,0.240577,0.0955339,-0.0731726,-0.268891,0.286034,-0.00324222,0.0715949,0.00951372,-0.264264,0.0809357,0.281736,-0.0522317,-0.0725454,0.155586,0.145319,-0.422852,-0.0786135,0.0592058,0.0551469,-0.0580283,0.239986,0.655173,0.205389,-0.407705,-0.190708,0.0468574,-0.15973,-0.18096,-0.22023,0.00762598,0.15569,-0.301933,0.373299,-0.231367,0.227162,-0.0913968,-0.121786,0.120698,-0.0335189,0.147112,-0.178737,0.00199152,-0.0430301,-0.190277,0.134796,0.0168629,0.282793,0.10819,0.263574,-0.164883,0.175074,-0.142265,-0.129775,-0.0732458,0.140089,-0.167261,-0.0647602,-0.426739,-0.214708,0.327249,-0.034509,-0.158162,-0.287791,0.114906,0.251653,0.190066,-0.0226798,-0.240586,0.000950442,0.0327124,0.194191,-0.219164,0.0392866,0.151794,0.030234,-0.120698,0.156,0.25278,-0.0961862,-0.290227,-0.278377,-0.141061,0.291765,-0.132253,-0.0972896,-0.0175776,-0.143369,0.322954,0.11416,0.42357,0.0449044,0.390758,0.0536391,-0.126077,-0.0381028,0.0695713,0.16292,-0.0850782,0.263394,-0.0160064,0.0622736,-0.0344804,0.268163,0.164225,0.0574142,-0.094438,-0.186363,-0.234571,0.247829,-0.408265,-0.0650311,-0.0948449,-0.161669,0.0286686,-0.172146,-0.123977,0.0909219,-0.0996168,-0.618804,-0.30482,0.011505,-0.23904,-0.0198757,0.00971699,0.293438,0.0348719,0.159984,-0.301334,-0.124777,0.125205,0.0922447,-0.122204,0.050242,0.129116,-0.352608,0.338201,-0.523917,0.201567,0.0189973,0.38268,-0.122076,0.318478,-0.0427491,-0.443433,0.115326,-0.193594,-0.0266444,-0.0993947,-0.175249,0.197564,0.200761,0.135956,0.080793,0.105797,-0.200467,-0.357003,0.0206236,-0.00311168,-0.0162265,-0.316308,0.141236,-0.153494,-0.148931,-0.419731,0.0222802,0.488687,-0.0539012,-0.29965,0.492413,0.222463,0.291657,0.131491,-0.109005,-0.342466,0.0798027,0.170754,-0.124134,0.0659238,0.171223,0.13671,0.0607108,0.195228,0.0210576,0.245909,-0.265166,-0.178537,0.0845442,0.200568,-0.171294,-0.243587,-0.149321,-0.062006,0.00291089,-0.0458287,-0.324011,-0.00707276,-0.0310984,0.253295,0.00475298,0.0369514,0.104256,0.167504,-0.0653243,0.20744,-0.0881677,-0.105102,0.349453,-0.0272161,0.295427,0.0647622,0.0831928,-0.270394,-0.503527,0.00680617,-0.108648,0.0477511,-0.109311,0.0605266,-0.10207,-0.297914,-0.298221,0.356072,0.156161,-0.0122296,-0.225525,-0.0060595,-0.196321,0.0897497,-0.472476,0.170852,0.156455,0.135512,0.0335582,-0.0411081,0.188172,-0.257526,0.380603,0.0503776,0.330682,-0.26744,0.0552105,0.143493,0.0119497,-0.0824797,-0.0301735,-0.270553,0.267186,0.402024,-0.232402,-0.612808,-0.336718,0.306555,0.00791041,0.127877,-0.324946,0.382771,0.670675,0.544245,-0.165519,0.179639,0.0906685,-0.00865161,-0.0156359,-0.287575,-0.13388,-0.0301384,-0.223741,-0.189086,-0.555997,-0.147495,0.397364,0.0516227,-0.0216236,-0.246825,-0.114385,-0.485944,-0.248573,0.164633,-0.0531763,0.0496491,-0.103967,0.181637,-0.199646,-0.0505959,0.0298787,0.290841,0.148684,-0.111278,-0.00446995,0.258528,-0.00876973,-0.0406859,-0.0245318,0.0855521,0.489643,0.216711,-0.297493,0.136479,-0.130025,-0.338054,0.0336512,0.207957,0.360921,0.235125,-0.0293919,0.176406,0.03129,-0.17496,-0.456127,0.0527941,-0.0523245,0.101331,0.0852728,0.0655681,-0.337849,-0.347727,0.13779,0.107254,-0.154059,-0.00586312,-0.0321602,0.0605635,0.345121,0.138611,0.022684,-0.158783,-0.000827872,0.0794254,0.256303,-0.363257,0.132955,0.0567933,0.3322,-0.214725,-0.221707,-0.374484,0.196394,0.11441,0.1173,-0.128748,0.0497128,-0.117515,-0.116237,0.230858,-0.255906,-0.294193,-0.294207,0.522761,-0.261846,0.0434503,-0.329043,0.0216975,0.211222,-0.210613,0.0585358,0.0402477,-0.256425,-0.0145168,-0.231604,0.29617,-0.443295,-0.315107,-0.0184921,-0.0608819,0.125721,0.0804491,0.156829,-0.0186372,0.027496,0.0503266,-0.196719,-0.213491,-0.263849,-0.160954,0.0566019,0.327596,-0.174447,0.22758,0.19063,0.157949,-0.161451,0.043118,0.0534048,-0.00260256,-0.123324,0.00248228,0.333946,0.0351711,0.0521366,0.123114,-0.398812,0.159151,0.0373609,-0.192224,-0.158132,-0.180606,0.0566063,-0.441742,0.134109,-0.1161,-0.00912082,-0.333867,0.299266,-0.0444247,0.102564,-0.476953,-0.142484,0.309214,-0.436821,-0.196522,-0.343091,0.0817717,0.0263065,-0.443496,0.0378762,0.111316,0.0225161,-0.268441,0.456304,-0.18565,0.246696,0.235687,0.171113,0.0207859,0.287453,0.0641379,0.356782,0.404775,-0.208987,-0.0712173,0.244443,-0.0928581,0.0179315,0.075961,-0.237191,0.0644254,0.0951106,-0.242083,0.196149,-0.288611,0.0543953,0.240931,-0.219592,0.0167073,-0.187704,-0.299625,0.170896,-0.165117,0.222876,-0.394924,-0.161659,-0.0963269,0.179419,0.110761,0.0744336,0.0491444,-0.299284,0.0507649,0.123781,0.130592,0.130289,0.450129,0.0622207,-0.0596099,0.0840725,0.0510298,0.230278,0.36098,0.377992,0.260317,0.203473,-0.167126,0.208157,-0.383896,0.177203,-0.00748924,-0.283109,-0.0563429,0.0217863,0.23237,0.0592641,0.147386,0.206538,-0.434,-0.0579965,-0.173778,0.309608,-0.483413,-0.127526,0.150586,-0.0591566,0.33798,0.0272265,0.101903,-0.0748959,-0.0611255,0.279562,0.35465,0.071339,-0.129358,-0.0309424,0.0466717,-0.163522,0.204242,-0.0840722,-0.0336923,-0.0640288,0.0255379,-0.0604485,0.222627,0.134082,0.301234,0.103918,-0.121457,-0.136746,0.188177,-0.00857605,-0.298033,-0.152736,0.115284,-0.0221039,-0.0967546,-0.0337277,-0.404526,-0.382787,0.00452444,-0.310355,-0.0492237,0.296822,0.0897112,0.0623481,-0.317909,0.095319,-0.0970796,0.166474,-0.550672,0.204118,-0.171661,-0.0431725,0.0393864,0.151764,-0.0340463,-0.132377,0.0951381,0.239036,-0.0520919,0.372271,-0.0444639,0.28327,0.176348,0.146018,0.197158,0.08811,0.190607,0.446387,-0.14305,-0.428583,-0.0964969,-0.0116021,0.0258474,-0.359076,-0.248162,0.506591,-0.201949,-0.042223,0.419076,-0.0408841,-0.0814484,0.174054,-0.0812973,-0.00800463,0.03112,0.130002,-0.00223776,-0.281933,0.14489,0.19822,0.046103,-0.242375,-0.302635,0.0330124,-0.311012,0.174835,0.202035,0.196391,-0.150511,0.0882783,0.0702109,-0.539388,0.0647053,0.434799,0.0945036,-0.209356,-0.510554,0.0584741,-0.00926378,-0.101631,0.0708718,-0.051681,0.230053,0.186325,-0.2551,0.148856,-0.0136673,0.252403,0.161474,0.0625672,-0.506106,-0.243953,0.120782,-0.251585,-0.127261,0.0528902,0.188617,-0.209702,-0.176748,0.197544,0.470847,0.14847,-0.0109865,0.27765,-0.237813,-0.0381337,0.0470131,0.0412289,-0.190531,0.00401083,0.457207,-0.157488,-0.479111,0.299836,-0.229633,-0.138938,0.180538,0.0930841,-0.0147255,-0.199082,0.340796,-0.0133366,-0.36985,0.0920877,-0.0651101,-0.136527,0.0443179,0.0340437,-0.369708,-0.142049,-0.470909,-0.0216584,0.00451017,-0.365728,-0.239617,-0.0552069,0.00581442,0.355666,0.21313,0.00941205,0.274424,-0.23906,-0.160089,0.0147677,0.436759,-0.108401,0.43423,0.0374352,-0.392995,0.317666,-0.404108,0.128958,0.0703809,0.00821086,-0.142379,0.176192,0.0568151,-0.272629,-0.0462158,0.0717741,-0.150352,0.11143,0.30969,-0.101046,-0.43065,0.102479,-0.00426548,-0.190855,-0.0473491,-0.140416,0.0746789,-0.270853,0.0444703,-0.096373,0.39044,0.0188541,-0.27114,-0.164362,-0.190691,-0.459627,-0.229393,-0.502283,-0.347374,-0.323519,-0.0808568,0.157559,-0.050088,0.377628,-0.160831,-0.0809752,0.232366,-0.181016,0.0137637,0.19802,-0.282429,-0.376115,-0.371134,-0.0874154,0.00796734,-0.265893,0.105705,0.0935532,-0.152804,-0.140156,-0.0932381,0.139076,-0.26447,0.330426,-0.480808,0.271871,-0.0407405,-0.0261485,-0.0855154,-0.114338,0.122435,0.0883467,-0.233596,-0.0294728,0.253097,0.242092,-0.324728,-0.0946485,0.202673,0.205186,-0.108409,0.00613019,0.226609,0.0249379,-0.177379,-0.0247689,-0.0806855,0.38347,0.247358,0.115176,0.20208,-0.0151675,0.309742,-0.242528,0.159352,-0.0669098,0.116088,-0.0416485,0.0388861,0.574309,-0.157143,-0.332058,-0.0691084,0.00985499,0.143128,0.1928,0.167426,0.102655,0.148689,-0.399164,-0.198667,0.241497,-0.32794,0.31795,-0.0617975,-0.194303,0.147404,0.0820693,0.0937334,0.0825667,-0.277508,-0.0362912,-0.0161358,-0.296181,0.191743,-0.0430768,0.12276,0.203344,0.203335,0.0294263,-0.164647,0.473035,0.31135,-0.019565,0.0159882,-0.120688,-0.160669,0.0705874,-0.457042,0.389855,-0.143589,-0.0392359,-0.176144,0.0147255,-0.0658708,-0.054752,-0.37105,-0.0972074,-0.203789,-0.503205,-0.22277,0.170576,0.15345,-0.276421,0.241997,-0.0427145,0.0265754,-0.0276817,-0.27162,0.196631,-0.248134,-0.301841,0.072842,0.385834,-0.0610126,0.00434084,-0.00232596,-0.34983,0.299881,0.175801,-0.134735,-0.12851,-0.309014,-0.449986,0.056858,-0.480458,0.0551333,-0.149706,0.0403691,0.0679511,0.213522,-0.147423,-0.488522,0.0720912,-0.0505287,-0.32015,0.152685,0.087354,0.282683,0.0914607,-0.394226,0.199562,0.0619494,-0.097818,-0.141058,-0.222707,-0.109031,0.024057,-0.15961,-0.122236,-0.0771097,-0.339608,0.0221059,-0.187084,0.259577,0.0122468,0.373894,-0.203188,0.168847,0.355291,-0.27305,-0.219427,0.13537,-0.415542,-0.103499,0.135644,-0.0705761,-0.0518953,-0.0127009,0.0545931,-0.0353469,0.158372,0.0535005,0.160102,-0.152314,-0.0458292,0.0958173,-0.0716363,0.159425,0.265341,-0.30876,-0.414503,-0.213325,0.262669,-0.0486422,0.0399826,-0.0939721,-0.128587,-0.0926972,-0.00607182,-0.383929,0.0907909,0.0617659,0.473274,0.244968,0.160982,0.252768,0.01475,0.202291,-0.0105935,0.133002,0.146254,0.279754,0.0100946,0.0258004,0.16917,-0.0744802,0.0975317,0.507966,-0.190405,-0.195165,-0.244408,0.335677,-0.170035,-0.103683,0.210925,-0.225625,-0.0791426,0.356186,0.208697,-0.10596,0.306259,-0.161362,0.27714,-0.0768044,0.171775,0.0160879,-0.135956,-0.174515,-0.0280331,0.16358,0.0976678,-0.143572,0.20029,-0.0671808,0.135378,-0.00820646,-0.159046,-0.040744,0.0966859,0.388358,-0.370479,-0.0535426,-0.228165,-0.0992646,-0.0669478,0.418891,-0.25385,-0.0218327,-0.291424,-0.0706706,-0.210757,-0.0780629,-0.127034,0.0444886,-0.192644,0.306845,-0.0475168,0.0326374,-0.402205,-0.0370148,-0.0847451,0.147534,-0.0312041,-0.0801772,0.074677,-0.215771,0.00457868,0.0465921,0.443114,-0.261163,0.250938,0.30622,0.0651913,0.27218,0.229975,-0.00615155,-0.272534,-0.0936477,0.0882333,-0.0572215,0.266976,0.402904,-0.0688855,0.164306,-0.0800064,-0.090876,0.074786,0.125555,0.0272068,0.0845328,0.392616,-0.136466,0.0599204,-0.0379249,0.319526,-0.286762,0.101211,0.0745673,-0.147389,-0.31519,0.416509,0.164855,-0.0223644\n",
    "])\n",
    "y_pred = tf.nn.softmax(logits * 20)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=56892, shape=(), dtype=float64, numpy=1.8969839241389832e-06>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=657, shape=(5, 3), dtype=float64, numpy=\narray([[  9.9983e-01,   1.2339e-04,   4.5392e-05],\n       [  9.1094e-04,   9.9897e-01,   1.2328e-04],\n       [  1.7148e-02,   4.6613e-02,   9.3624e-01],\n       [  7.5510e-02,   9.1990e-01,   4.5918e-03],\n       [  4.7123e-02,   9.4650e-01,   6.3775e-03]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.6880e-04,   1.2340e-04,   4.5393e-05],\n       [  9.1135e-04,   1.0348e-03,   1.2329e-04],\n       [  1.7297e-02,   4.7734e-02,   6.5884e-02],\n       [  2.5835e+00,   8.3492e-02,   4.6023e-03],\n       [  4.8270e-02,   5.4985e-02,   6.3979e-03]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E1 = -y*np.log(y_pred)-(1-y)*np.log(1-y_pred)\n",
    "E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.6880e-04,  -0.0000e+00,  -0.0000e+00],\n       [ -0.0000e+00,  -1.0348e-03,  -0.0000e+00],\n       [ -0.0000e+00,  -0.0000e+00,  -6.5884e-02],\n       [ -2.5835e+00,  -8.3492e-02,  -0.0000e+00],\n       [ -0.0000e+00,  -5.4985e-02,  -0.0000e+00]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y*np.log(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.175245341407356"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1.8969839241389832e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.6880e-04,   1.0348e-03,   6.5884e-02,   2.6670e+00,   5.4985e-02])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E1 = -np.sum(y*np.log(y_pred), 1)\n",
    "E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n[[ 1.      0.9526  0.8808]\n [ 0.9526  1.      0.7311]\n [ 0.7311  0.8808  0.9933]\n [ 0.982   0.9985  0.7685]\n [ 0.9526  0.9975  0.7311]], shape=(5, 3), dtype=float64)\n[[  6.1442e-06   3.0486e+00   2.1269e+00]\n [  3.0486e+00   4.5399e-05   1.3133e+00]\n [  1.3133e+00   2.1269e+00   6.7153e-03]\n [  1.8150e-02   1.5023e-03   1.4633e+00]\n [  3.0486e+00   2.4757e-03   1.3133e+00]]\ntf.Tensor(\n[[  6.1442e-06   3.0486e+00   2.1269e+00]\n [  3.0486e+00   4.5399e-05   1.3133e+00]\n [  1.3133e+00   2.1269e+00   6.7153e-03]\n [  1.8150e-02   1.5023e-03   1.4633e+00]\n [  3.0486e+00   2.4757e-03   1.3133e+00]], shape=(5, 3), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57185, shape=(5,), dtype=float64, numpy=array([ 5.1755,  4.3619,  3.4469,  1.4829,  4.3643])>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,0]])\n",
    "logits = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "y_pred = tf.nn.sigmoid(logits)\n",
    "E1 = -y*np.log(y_pred)-(1-y)*np.log(1-y_pred)\n",
    "y = np.array(y).astype(np.float64)  #label是float64\n",
    "E2 = tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "print(y_pred)\n",
    "print(E1)\n",
    "print(E2)\n",
    "tf.reduce_sum(E2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict:\n  tf.Tensor(\n[[ 0.1146  0.1037  0.1146  0.1146  0.0939  0.1146  0.1146  0.1146  0.1146]\n [ 0.111   0.1227  0.111   0.1004  0.111   0.111   0.111   0.111   0.111 ]], shape=(2, 9), dtype=float64)\nE1:  [ 2.166   2.0983]\nE2:  tf.Tensor([ 2.166   2.0983], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0]])# 每一行只有一个1\n",
    "logits =np.array([[1.0,0.9,1,1,0.8,1,1,1,1],[1,1.1,1,0.9,1,1,1,1,1]])\n",
    "y_pred =tf.nn.softmax(logits)\n",
    "E1 = -np.sum(y*np.log(y_pred),-1)\n",
    "y = np.array(y).astype(np.float64)\n",
    "E2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)\n",
    "print(\"y_predict:\\n \", y_pred)\n",
    "print(\"E1: \",E1)\n",
    "print(\"E2: \", E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict:\n  tf.Tensor(\n[[ 0.3333  0.3333  0.3333]\n [ 0.3333  0.3333  0.3333]\n [ 0.3333  0.3333  0.3333]\n [ 0.3333  0.3333  0.3333]\n [ 0.3333  0.3333  0.3333]], shape=(5, 3), dtype=float64)\nE1:  [ 1.0986  1.0986  1.0986  1.0986  1.0986]\nE2:  tf.Tensor([ 1.0986  1.0986  1.0986  1.0986  1.0986], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0]])# 每一行只有一个1\n",
    "logits =np.array([[1.0,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1]])\n",
    "y_pred =tf.nn.softmax(logits)\n",
    "E1 = -np.sum(y*np.log(y_pred),-1)\n",
    "y = np.array(y).astype(np.float64)\n",
    "E2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)\n",
    "print(\"y_predict:\\n \", y_pred)\n",
    "print(\"E1: \",E1)\n",
    "print(\"E2: \", E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=496, shape=(5,), dtype=float64, numpy=array([  1.6880e-04,   1.0348e-03,   6.5884e-02,   2.6670e+00,   5.4985e-02])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12. ,   3. ,   2. ],\n       [  3. ,  10. ,   1. ],\n       [  1. ,   2. ,   5. ],\n       [  4. ,   6.5,   1.2],\n       [  3. ,   6. ,   1. ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57014, shape=(5,), dtype=float64, numpy=array([ 12. ,  10. ,   5. ,   6.5,   6. ])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Invalid reduction dimension (1 for input with 1 dimension(s) [Op:Max]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-c2d1e8d462d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloss_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mloss_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_max\u001b[1;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[0;32m   1638\u001b[0m                                                   reduction_indices),\n\u001b[0;32m   1639\u001b[0m                                    \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                                    name=name))\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_max\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m   4662\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4663\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4664\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension (1 for input with 1 dimension(s) [Op:Max]"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "loss_p=tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)\n",
    "loss_r = tf.reduce_max(loss_p, 1)\n",
    "loss_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[0,0,0,1,0,0,0]] )\n",
    "logits = np.array([[0.92595,1.11746e-09,1.02595e-06,1.02595e-06, 1.11746e-09,1.02595e-06,1.11746e-09]])\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y = np.array(y).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=468, shape=(1, 7), dtype=float64, numpy=array([[ 0.2961,  0.1173,  0.1173,  0.1173,  0.1173,  0.1173,  0.1173]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=498, shape=(1,), dtype=float64, numpy=array([ 2.1429])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(1,), dtype=int32, numpy=array([3])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()\n",
    "x=[[2.]]\n",
    "m=tf.matmul(x,x)\n",
    "y= 1\n",
    "z=2\n",
    "m =tf.add(z,y)\n",
    "n=tf.reshape(m, [1,])\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.57735027  0.57735027]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n  DeprecationWarning)\nD:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by the normalize function.\n  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "data = np.array([\n",
    "    [1, 1, 1],\n",
    "    [765, 5, 0.35],\n",
    "    [800, 7, 0.09], ])\n",
    "data1=np.array([1,1,1])\n",
    "#data1=data1.reshape(1, -1)\n",
    "data = normalize(data1, axis=1, norm='l2')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n(3, 1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1, 4],\n        [2, 2],\n        [3, 2]],\n\n       [[2, 2],\n        [4, 1],\n        [6, 1]],\n\n       [[3, 2],\n        [6, 1],\n        [9, 1]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[1,2],[2,1],[3,1]])\n",
    "y=np.array([[[1,2]],[[2,1]],[[3,1]]])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['vids', 'vidMedias', 'vidCate1s', 'vidCate2s', 'vid', 'media', 'cate1', 'cate2', 'tag',\n",
    "                'pubtime', 'devid', 'province', 'city', 'profession', 'age', 'gender',\n",
    "                'cate1_weight_info', 'cate2_weight_info', 'media_weight_info',\n",
    "                'tag_weight_info', 'cate1_ext_weight_info', 'cate2_ext_weight_info', 'media_ext_weight_info',\n",
    "                'tag_ext_weight_info', 'cate1_lst_weight_info', 'cate2_lst_weight_info',\n",
    "                'media_lst_weight_info', 'tag_lst_weight_info', 'hg_cate1_weight_info',\n",
    "                'hg_cate2_weight_info', 'hg_media_weight_info', 'hg_cate1_ext_weight_info',\n",
    "                'hg_cate2_ext_weight_info', 'hg_media_ext_weight_info', 'hg_cate1_lst_weight_info',\n",
    "                'hg_cate2_lst_weight_info', 'hg_media_lst_weight_info']\n",
    "_CSV_COLUMN_DEFAULTS = [[''], [''], [''], [''], [''], [''], [0], [''], [''],\n",
    "                    [''], [''], [0], [''], [0], [-1], [''],\n",
    "                    [''], [''], [''],\n",
    "                    [''], [''], [''], [''],\n",
    "                    [''], [''], [''],\n",
    "                    [''], [''], [''],\n",
    "                    [''], [''], [''],\n",
    "                    [''], [''], [''],\n",
    "                    [''], ['']]\n",
    "dataset = tf.data.TextLineDataset('D:\\workPlace\\gitCode\\python-lorineluo-dev\\src\\main\\python\\youtube\\data\\yoo\\yoo_16')\n",
    "\n",
    "def parse_csv(value):\n",
    "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS,\n",
    "                            field_delim='\\t', na_value='')\n",
    "    print(len(columns))\n",
    "    for c in columns:\n",
    "        print(tf.shape(c))\n",
    "        # cc = tf.Print(c, [c])\n",
    "        # print(cc + \"\")\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, columns))\n",
    "    # features.pop('label')\n",
    "    sparse_list = ['vids', 'vidMedias', 'vidCate1s', 'vidCate2s', 'tag',\n",
    "                   'cate1_weight_info', 'cate2_weight_info', 'media_weight_info',\n",
    "                   'tag_weight_info', 'cate1_ext_weight_info', 'cate2_ext_weight_info', 'media_ext_weight_info',\n",
    "                   'tag_ext_weight_info', 'cate1_lst_weight_info', 'cate2_lst_weight_info',\n",
    "                   'media_lst_weight_info', 'tag_lst_weight_info', 'hg_cate1_weight_info',\n",
    "                   'hg_cate2_weight_info', 'hg_media_weight_info', 'hg_cate1_ext_weight_info',\n",
    "                   'hg_cate2_ext_weight_info', 'hg_media_ext_weight_info', 'hg_cate1_lst_weight_info',\n",
    "                   'hg_cate2_lst_weight_info', 'hg_media_lst_weight_info']\n",
    "    # delimiter_list = [',', ',', ',', ',', ',', ',']\n",
    "    # default_values = ['', , 0, 0, 0, 0]\n",
    "    for i in range(len(sparse_list)):\n",
    "        sparse = sparse_list[i]\n",
    "        # delim = delimiter_list[i]\n",
    "        #v = tf.reshape(features[sparse], [])\n",
    "        print(features[sparse])\n",
    "        # print(v)\n",
    "        sparse_tensor = tf.string_split(features[sparse], delimiter=',')\n",
    "        if sparse in [\"vidCate1s\", \"cate1_weight_info\"]:\n",
    "            features[sparse] = tf.strings.to_number(\n",
    "                tf.sparse_to_dense(sparse_tensor.indices,\n",
    "                                   sparse_tensor.dense_shape,\n",
    "                                   sparse_tensor.values,\n",
    "                                   default_value='0'), out_type=tf.int32)\n",
    "        else:\n",
    "            features[sparse] =tf.sparse_to_dense(sparse_tensor.indices,\n",
    "                               sparse_tensor.dense_shape,\n",
    "                               sparse_tensor.values,\n",
    "                               default_value='')\n",
    "\n",
    "    print(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\nTensor(\"Shape:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_1:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_2:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_3:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_4:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_5:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_6:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_7:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_8:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_9:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_10:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_11:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_12:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_13:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_14:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_15:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_16:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_17:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_18:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_19:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_20:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_21:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_22:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_23:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_24:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_25:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_26:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_27:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_28:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_29:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_30:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_31:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_32:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_33:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_34:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_35:0\", shape=(0,), dtype=int32)\nTensor(\"Shape_36:0\", shape=(0,), dtype=int32)\nTensor(\"DecodeCSV:0\", shape=(), dtype=string)\nTensor(\"Reshape:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:1\", shape=(), dtype=string)\nTensor(\"Reshape_1:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:2\", shape=(), dtype=string)\nTensor(\"Reshape_2:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:3\", shape=(), dtype=string)\nTensor(\"Reshape_3:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:8\", shape=(), dtype=string)\nTensor(\"Reshape_4:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:16\", shape=(), dtype=string)\nTensor(\"Reshape_5:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:17\", shape=(), dtype=string)\nTensor(\"Reshape_6:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:18\", shape=(), dtype=string)\nTensor(\"Reshape_7:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:19\", shape=(), dtype=string)\nTensor(\"Reshape_8:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:20\", shape=(), dtype=string)\nTensor(\"Reshape_9:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:21\", shape=(), dtype=string)\nTensor(\"Reshape_10:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:22\", shape=(), dtype=string)\nTensor(\"Reshape_11:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:23\", shape=(), dtype=string)\nTensor(\"Reshape_12:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:24\", shape=(), dtype=string)\nTensor(\"Reshape_13:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:25\", shape=(), dtype=string)\nTensor(\"Reshape_14:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:26\", shape=(), dtype=string)\nTensor(\"Reshape_15:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:27\", shape=(), dtype=string)\nTensor(\"Reshape_16:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:28\", shape=(), dtype=string)\nTensor(\"Reshape_17:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:29\", shape=(), dtype=string)\nTensor(\"Reshape_18:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:30\", shape=(), dtype=string)\nTensor(\"Reshape_19:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:31\", shape=(), dtype=string)\nTensor(\"Reshape_20:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:32\", shape=(), dtype=string)\nTensor(\"Reshape_21:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:33\", shape=(), dtype=string)\nTensor(\"Reshape_22:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:34\", shape=(), dtype=string)\nTensor(\"Reshape_23:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:35\", shape=(), dtype=string)\nTensor(\"Reshape_24:0\", shape=(1,), dtype=string)\nTensor(\"DecodeCSV:36\", shape=(), dtype=string)\nTensor(\"Reshape_25:0\", shape=(1,), dtype=string)\n{'vids': <tf.Tensor 'SparseToDense:0' shape=(?, ?) dtype=string>, 'vidMedias': <tf.Tensor 'SparseToDense_1:0' shape=(?, ?) dtype=string>, 'vidCate1s': <tf.Tensor 'StringToNumber:0' shape=(?, ?) dtype=int32>, 'vidCate2s': <tf.Tensor 'SparseToDense_3:0' shape=(?, ?) dtype=string>, 'vid': <tf.Tensor 'DecodeCSV:4' shape=() dtype=string>, 'media': <tf.Tensor 'DecodeCSV:5' shape=() dtype=string>, 'cate1': <tf.Tensor 'DecodeCSV:6' shape=() dtype=int32>, 'cate2': <tf.Tensor 'DecodeCSV:7' shape=() dtype=string>, 'tag': <tf.Tensor 'SparseToDense_4:0' shape=(?, ?) dtype=string>, 'pubtime': <tf.Tensor 'DecodeCSV:9' shape=() dtype=string>, 'devid': <tf.Tensor 'DecodeCSV:10' shape=() dtype=string>, 'province': <tf.Tensor 'DecodeCSV:11' shape=() dtype=int32>, 'city': <tf.Tensor 'DecodeCSV:12' shape=() dtype=string>, 'profession': <tf.Tensor 'DecodeCSV:13' shape=() dtype=int32>, 'age': <tf.Tensor 'DecodeCSV:14' shape=() dtype=int32>, 'gender': <tf.Tensor 'DecodeCSV:15' shape=() dtype=string>, 'cate1_weight_info': <tf.Tensor 'StringToNumber_1:0' shape=(?, ?) dtype=int32>, 'cate2_weight_info': <tf.Tensor 'SparseToDense_6:0' shape=(?, ?) dtype=string>, 'media_weight_info': <tf.Tensor 'SparseToDense_7:0' shape=(?, ?) dtype=string>, 'tag_weight_info': <tf.Tensor 'SparseToDense_8:0' shape=(?, ?) dtype=string>, 'cate1_ext_weight_info': <tf.Tensor 'SparseToDense_9:0' shape=(?, ?) dtype=string>, 'cate2_ext_weight_info': <tf.Tensor 'SparseToDense_10:0' shape=(?, ?) dtype=string>, 'media_ext_weight_info': <tf.Tensor 'SparseToDense_11:0' shape=(?, ?) dtype=string>, 'tag_ext_weight_info': <tf.Tensor 'SparseToDense_12:0' shape=(?, ?) dtype=string>, 'cate1_lst_weight_info': <tf.Tensor 'SparseToDense_13:0' shape=(?, ?) dtype=string>, 'cate2_lst_weight_info': <tf.Tensor 'SparseToDense_14:0' shape=(?, ?) dtype=string>, 'media_lst_weight_info': <tf.Tensor 'SparseToDense_15:0' shape=(?, ?) dtype=string>, 'tag_lst_weight_info': <tf.Tensor 'SparseToDense_16:0' shape=(?, ?) dtype=string>, 'hg_cate1_weight_info': <tf.Tensor 'SparseToDense_17:0' shape=(?, ?) dtype=string>, 'hg_cate2_weight_info': <tf.Tensor 'SparseToDense_18:0' shape=(?, ?) dtype=string>, 'hg_media_weight_info': <tf.Tensor 'SparseToDense_19:0' shape=(?, ?) dtype=string>, 'hg_cate1_ext_weight_info': <tf.Tensor 'SparseToDense_20:0' shape=(?, ?) dtype=string>, 'hg_cate2_ext_weight_info': <tf.Tensor 'SparseToDense_21:0' shape=(?, ?) dtype=string>, 'hg_media_ext_weight_info': <tf.Tensor 'SparseToDense_22:0' shape=(?, ?) dtype=string>, 'hg_cate1_lst_weight_info': <tf.Tensor 'SparseToDense_23:0' shape=(?, ?) dtype=string>, 'hg_cate2_lst_weight_info': <tf.Tensor 'SparseToDense_24:0' shape=(?, ?) dtype=string>, 'hg_media_lst_weight_info': <tf.Tensor 'SparseToDense_25:0' shape=(?, ?) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(parse_csv, num_parallel_calls=1)\n",
    "batched = dataset.apply(tf.contrib.data.batch_and_drop_remainder(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vids': <tf.Tensor: id=660, shape=(30, 10), dtype=string, numpy=\narray([[b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'm0748qzgk34', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'i0777262mmv', b'e0788mbrgs1', b'', b'', b'', b'', b'', b'', b'',\n        b''],\n       [b'g08035twn9o', b'u080589zke2', b'h0770291jjn', b'', b'', b'', b'',\n        b'', b'', b''],\n       [b'o0786t0t6rx', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'e0810u4oufw', b'r0807j6xkwu', b'v079754ekgr', b'u08089g8fbi',\n        b'v0763obv8wd', b'l0787qhgqao', b'o0807ra98l5', b'h0809ga1h7a',\n        b'x07619wjyq5', b'c0775yay4qy'],\n       [b'c0803ws8gh0', b'z0748dp8xj4', b'p0718w7b671', b'c1429u92bwl',\n        b'o0804nfr3hl', b'j0796osfes0', b'o0774re5dlz', b'f08031jbktj',\n        b'u0780w2pbmf', b't0740agned5'],\n       [b'g0769k24hja', b't0806savhzi', b'f0736z5d4e6', b'p0792xeks1e',\n        b'i0714pazpzy', b'g0766rxzaej', b'l0760j74lam', b'm0810wvaxpz',\n        b'd0793jvqdi2', b'l0764vmoimg'],\n       [b'd0789stc5de', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b't0756s8x0w1', b'd0787er5xrn', b'b0760bbyh7t', b'i0781wdjqyz',\n        b'a0789cn4v1h', b'b071046eppg', b'l0789omok6a', b'i0742ow73tz',\n        b'y0789k38rah', b't0811ukqc2t'],\n       [b'e0734lf5t9n', b'p0788j899ne', b'h0773mvk8gu', b'e0801ptgivt',\n        b'y0745oelsj2', b't0790835f67', b'w0791w6l32b', b'w0791f96pd8',\n        b'c0792u061ve', b'w07941kdujx'],\n       [b'w07948s421f', b'z06678nikpb', b't0667orn81g', b'q062521hy8n',\n        b'g0785q0lpbe', b'j0793vfvq34', b'', b'', b'', b''],\n       [b'x0690rn6on5', b'q0789v8v4y7', b'x0538bgjegq', b'a0706lnnjle',\n        b'r0800f444id', b'y0674p7rpo0', b'o0796vu7hi5', b'f08114e0it1',\n        b'g06729atkei', b'k0736qs2w1f'],\n       [b'q08079odxg1', b'q0601i4tbcj', b'i0757jhou54', b'x0800b5tljk',\n        b'a0660a91rp6', b'g0799dc6jc4', b'y0798r5wwrr', b'w0810igffbk',\n        b'q0660g3pk8g', b'r0528s9lvup'],\n       [b'f0749yida41', b'u0802dqfwqq', b'm0782jdew56', b'f07414legid',\n        b's0805odhgwp', b'', b'', b'', b'', b''],\n       [b'n0789vuabi7', b'o0796vu7hi5', b's05279g7hms', b'j0733yabi5c',\n        b'b0797sfbshx', b'q0796kp7c01', b'', b'', b'', b''],\n       [b'b0785xyduej', b'r08112gbzty', b'd07948hktxh', b'f0540jasmkk',\n        b'a07565w6p65', b'u0795wckt6q', b's0810qj6yst', b'', b'', b''],\n       [b'j0793438mb2', b'i08094dckm8', b's08073kpf5o', b's08073kpf5o',\n        b'g08059wmxt7', b'z07926ou26p', b'h072825q1mq', b'i0753oqnaio',\n        b'r0747cw23p5', b'o0557k30y3e'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'p0735m5xu98', b'd0800nx3inj', b'k0541j25db2', b'c07734xaw1i',\n        b'c0768r4z0qk', b'', b'', b'', b'', b''],\n       [b'u0750ley2t5', b'g0804ahxhqb', b'v0755i42xcd', b'i0764yf61cu',\n        b'k0727dtdiia', b'e07945yh64l', b'u0793y3x3qy', b'm07837h3dih',\n        b't0512j0ehed', b'k0789dtri2n'],\n       [b'f0790d2yocc', b'o0809mbpj9g', b'm0811kx1zs8', b'm0811kx1zs8',\n        b'n072614yx9s', b'a0788jd7h71', b'm076081mvcg', b'n05396gron9',\n        b'k05626ttjsh', b'z0806pd5nea'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'a0752jzhv2f', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'd0553t3u4p4', b'd0800jchtel', b'j076761971q', b'i0781efda9h',\n        b'k0801pxu70f', b'', b'', b'', b'', b''],\n       [b's0781rmplz7', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'q0810qdta9f', b's0781rmplz7', b'', b'', b'', b'', b'', b'', b'',\n        b''],\n       [b'r0788nhday5', b'm0730297fnm', b'r0800osfth8', b'i0799u17976',\n        b'y0807uzzoax', b'p0552yxm5nr', b'q0739cqg3v8', b'w08054topvu',\n        b'a0786ncmgbc', b'b0808neisbb'],\n       [b'l07130oilcm', b'h0786rj9i18', b'r0765z0vmga', b'z08116oaavd',\n        b'z08116oaavd', b'f0759pgnlo4', b'z07926ou26p', b'v0798x6gwfx',\n        b'e0624yqdano', b'l07978d11bp'],\n       [b'y0706oo52xz', b'q078345rvnb', b'q078345rvnb', b'u079712hwg5',\n        b'o0557k30y3e', b's0806hvcw8r', b'a0789sw0q9x', b'r07990h92d3',\n        b'l05066mq6wo', b'q0552zighgt']], dtype=object)>, 'vidMedias': <tf.Tensor: id=659, shape=(30, 10), dtype=string, numpy=\narray([[b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'5204461', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'6589564', b'6576866', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'6321708', b'6321708', b'6448923', b'', b'', b'', b'', b'', b'',\n        b''],\n       [b'5210130', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'10297266', b'5651930', b'5783538', b'14214418', b'5210130',\n        b'5671702', b'5580978', b'0', b'8534317', b'7611417'],\n       [b'6448923', b'5210130', b'8534317', b'5005933', b'5135259',\n        b'5664291', b'9967638', b'0', b'10414649', b'5664291'],\n       [b'5210130', b'0', b'8534317', b'5487091', b'5135259', b'0',\n        b'7579159', b'5616271', b'9883556', b'6861607'],\n       [b'6294804', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'6060364', b'6294804', b'0', b'5912001', b'6294804', b'6497204',\n        b'6408563', b'6438268', b'8143671', b'5950841'],\n       [b'5474011', b'6373130', b'6352683', b'0', b'6438268', b'6748934',\n        b'6932951', b'6294804', b'5701086', b'0'],\n       [b'6201711', b'5387456', b'5387456', b'5713693', b'6201711',\n        b'6201711', b'', b'', b'', b''],\n       [b'5387456', b'6201711', b'5351833', b'5387456', b'6201711',\n        b'5387456', b'6201711', b'5713693', b'5713693', b'0'],\n       [b'5387456', b'5713693', b'5713693', b'6201711', b'5387456',\n        b'6201711', b'0', b'5387456', b'5887714', b'5713693'],\n       [b'0', b'6079186', b'6354161', b'11798358', b'5472357', b'', b'',\n        b'', b'', b''],\n       [b'6421472', b'6201711', b'5377137', b'5701086', b'5209370',\n        b'10128240', b'', b'', b'', b''],\n       [b'9987256', b'5644159', b'6391643', b'6146900', b'6391643',\n        b'6391643', b'5590224', b'', b'', b''],\n       [b'5644571', b'5780076', b'5644159', b'5644159', b'5058888',\n        b'6391643', b'6557077', b'6391643', b'6391643', b'6483818'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'5500247', b'14214363', b'5351833', b'7128808', b'0', b'', b'',\n        b'', b'', b''],\n       [b'0', b'5230017', b'6643002', b'6358822', b'0', b'7579159',\n        b'10344700', b'6547795', b'5351833', b'10513707'],\n       [b'10297266', b'5135259', b'0', b'0', b'0', b'10713009',\n        b'10719724', b'5351833', b'5351833', b'6103146'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'5469814', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'5460042', b'0', b'6321789', b'5582117', b'5827631', b'', b'',\n        b'', b'', b''],\n       [b'9934363', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'5474011', b'9934363', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'6212171', b'10297266', b'6454567', b'8868741', b'5553869',\n        b'6483818', b'10021513', b'0', b'6344906', b'6391643'],\n       [b'5210130', b'5908841', b'7463731', b'5290351', b'5290351',\n        b'10310962', b'6391643', b'11758818', b'6391643', b'5568463'],\n       [b'8652800', b'5303630', b'5303630', b'10297266', b'6483818',\n        b'5788087', b'7788003', b'8829780', b'5458425', b'6483818']], dtype=object)>, 'vidCate1s': <tf.Tensor: id=657, shape=(30, 10), dtype=int32, numpy=\narray([[      0,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494452,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494451, 1494447,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494451, 1494451, 1494451,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494446,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [8070000, 8060000, 1494467, 1494452, 8070000, 1494462, 8060000,\n              0, 1494462, 1494468],\n       [1494458, 8070000, 1494452, 1494453, 1494470, 8060000, 8140000,\n              0, 8140000, 1494452],\n       [8070000,       0, 1494458, 1494452, 8150000, 1494462, 1494452,\n        8150000, 1494462, 8060000],\n       [1494451,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494459, 1494451,       0, 1494462, 1494451, 1494449, 1494447,\n        1494461, 1494462, 1494451],\n       [1494466, 1494466, 1494461,       0, 1494461, 1494459, 1494462,\n        1494451, 1494447,       0],\n       [1494451, 1494451, 1494451, 1494452, 1494451, 1494451,       0,\n              0,       0,       0],\n       [1494451, 1494451, 1494451, 1494451, 1494451, 1494451, 1494451,\n        1494449, 1494449,       0],\n       [1494451, 1494452, 1494449, 1494451, 1494451, 1494451,       0,\n        1494451, 1494452, 1494452],\n       [      0, 1494464, 1494464, 1494450, 1494464,       0,       0,\n              0,       0,       0],\n       [1494447, 1494451, 1494451, 1494462, 1494451, 1494451,       0,\n              0,       0,       0],\n       [1494464, 1494461, 1494463, 1494463, 1494463, 1494463, 1494461,\n              0,       0,       0],\n       [1494463, 1494461, 1494461, 1494461, 1494464, 1494463, 1494461,\n        1494463, 1494463, 1494452],\n       [      0,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494454, 1494456, 1494451, 1494462,       0,       0,       0,\n              0,       0,       0],\n       [      0, 8070000, 1528271, 1494462,       0, 8130000, 1494462,\n        1494462, 1494451, 1494462],\n       [1494462, 8070000,       0,       0,       0, 1494462, 8070000,\n        1494451, 1494451, 8070000],\n       [      0,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494452,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494451,       0, 1494461, 1494460, 1494449,       0,       0,\n              0,       0,       0],\n       [1494464,       0,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494456, 1494464,       0,       0,       0,       0,       0,\n              0,       0,       0],\n       [1494451, 8070000, 1494453, 1494452, 1494453, 1494452, 1494462,\n              0, 1494464, 1494463],\n       [8070000, 1494461, 1494452, 1494461, 1494461, 8070000, 1494463,\n        1494461, 1494463, 1494452],\n       [1494461, 1494463, 1494463, 1494457, 1494452, 1494465, 1494464,\n        1494464, 1494452, 1494452]])>, 'vidCate2s': <tf.Tensor: id=658, shape=(30, 10), dtype=string, numpy=\narray([[b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494541', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494517', b'1494490', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494517', b'1494517', b'1494517', b'', b'', b'', b'', b'', b'',\n        b''],\n       [b'1528261', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'8070100', b'8069900', b'1538940', b'1494519', b'8070200',\n        b'1494482', b'8060200', b'0', b'1494482', b'1494578'],\n       [b'8020200', b'8070100', b'1494552', b'8179900', b'1494434',\n        b'8060200', b'8149900', b'0', b'8149900', b'1494519'],\n       [b'8070100', b'0', b'1494572', b'1494541', b'8159900', b'8100500',\n        b'1494519', b'8159900', b'8100400', b'8069900'],\n       [b'1494517', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494531', b'1494517', b'0', b'1494482', b'1494517', b'1494439',\n        b'1494490', b'1494497', b'1494482', b'1494517'],\n       [b'1494564', b'1494564', b'1494546', b'0', b'1494523', b'1494531',\n        b'1494482', b'1494517', b'1494494', b'0'],\n       [b'1494487', b'1494517', b'1494517', b'1497226', b'1496638',\n        b'1496638', b'', b'', b'', b''],\n       [b'1494517', b'1494487', b'1496637', b'1494517', b'1494517',\n        b'1494517', b'1496637', b'1494438', b'1494438', b'0'],\n       [b'1494517', b'1497226', b'1494439', b'1494517', b'1494517',\n        b'1496637', b'0', b'1494517', b'1494552', b'1494552'],\n       [b'0', b'1494428', b'1494428', b'1494441', b'1494427', b'', b'',\n        b'', b'', b''],\n       [b'1494490', b'1496637', b'1496637', b'1494482', b'1494487',\n        b'1496637', b'', b'', b'', b''],\n       [b'1494428', b'1494589', b'1494423', b'1494423', b'1494423',\n        b'1494423', b'1494589', b'', b'', b''],\n       [b'1494423', b'1494589', b'1494589', b'1494589', b'1494429',\n        b'1494423', b'1494546', b'1494423', b'1494423', b'1494541'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494527', b'1494504', b'1496637', b'1494520', b'0', b'', b'',\n        b'', b'', b''],\n       [b'0', b'8070100', b'1528268', b'1494482', b'0', b'8130300',\n        b'8100400', b'1494520', b'1496637', b'8100400'],\n       [b'8100500', b'8070100', b'0', b'0', b'0', b'8100400', b'8070100',\n        b'1496637', b'1496637', b'8070100'],\n       [b'', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494519', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494517', b'0', b'1494546', b'1494553', b'1494439', b'', b'',\n        b'', b'', b''],\n       [b'1494428', b'', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494504', b'1494428', b'', b'', b'', b'', b'', b'', b'', b''],\n       [b'1494517', b'8070200', b'1528264', b'1494541', b'1528264',\n        b'1494541', b'1494520', b'0', b'1494429', b'1494423'],\n       [b'8070100', b'1494589', b'1494541', b'1494589', b'1494589',\n        b'8070200', b'1494423', b'1494589', b'1494423', b'1494541'],\n       [b'1494589', b'1494423', b'1494423', b'1494530', b'1494541',\n        b'1494566', b'1494429', b'1494429', b'1494552', b'1494541']], dtype=object)>, 'vid': <tf.Tensor: id=656, shape=(30,), dtype=string, numpy=\narray([b's0781rmplz7', b'v0726g32b3r', b'r0787fji91z', b'b0714m7ye70',\n       b'u07492npm2t', b'u07492npm2t', b'u07492npm2t', b'u07492npm2t',\n       b'k0725gaij1q', b'k0725gaij1q', b'k0725gaij1q', b'o080614li6h',\n       b'o080614li6h', b'o080614li6h', b'm0766i9130s', b'c0701vv67qd',\n       b'j07734d9m62', b'j07734d9m62', b'd0757ilpdw3', b'r0810pu9agt',\n       b'r0810pu9agt', b'r0810pu9agt', b'g08054t4brq', b'v07607aqb8k',\n       b'j0784fkn0go', b'm0766i9130s', b'i0791cyxipj', b'i0791cyxipj',\n       b'i0791cyxipj', b'i0791cyxipj'], dtype=object)>, 'media': <tf.Tensor: id=645, shape=(30,), dtype=string, numpy=\narray([b'9934363', b'6448923', b'6894132', b'5463227', b'5050512',\n       b'5050512', b'5050512', b'5050512', b'5434678', b'5434678',\n       b'5434678', b'6201711', b'6201711', b'6201711', b'6342468',\n       b'5377137', b'10297266', b'10297266', b'7755956', b'5698114',\n       b'5698114', b'5698114', b'5200831', b'11796886', b'7431582',\n       b'6342468', b'5392652', b'5392652', b'5392652', b'5392652'], dtype=object)>, 'cate1': <tf.Tensor: id=625, shape=(30,), dtype=int32, numpy=\narray([1494464, 8010000, 1494451, 1494451, 1494470, 1494470, 1494470,\n       1494470, 1494447, 1494447, 1494447, 1494451, 1494451, 1494451,\n       1494464, 1494451, 1494453, 1494453, 1494462, 1494451, 1494451,\n       1494451, 1494451, 8150000, 1528271, 1494464, 1494461, 1494461,\n       1494461, 1494461])>, 'cate2': <tf.Tensor: id=629, shape=(30,), dtype=string, numpy=\narray([b'1494428', b'8019900', b'0', b'1494517', b'1494434', b'1494434',\n       b'1494434', b'1494434', b'1494494', b'1494494', b'1494494',\n       b'1494517', b'1494517', b'1494517', b'1494428', b'1496637',\n       b'8179900', b'8179900', b'1494520', b'1496638', b'1496638',\n       b'1496638', b'1496638', b'8150300', b'1528268', b'1494428',\n       b'1494589', b'1494589', b'1494589', b'1494589'], dtype=object)>, 'tag': <tf.Tensor: id=652, shape=(30, 7), dtype=string, numpy=\narray([[b'292672', b'90306', b'94807', b'55805461', b'55805516',\n        b'55751139', b''],\n       [b'421871', b'3935330', b'55790292', b'101458', b'', b'', b''],\n       [b'102389', b'55812192', b'786727', b'224946', b'', b'', b''],\n       [b'101234', b'230066', b'50027445', b'230086', b'55776852',\n        b'4915002', b''],\n       [b'40380595', b'4093463', b'9588009', b'1073741826', b'', b'', b''],\n       [b'40380595', b'4093463', b'9588009', b'1073741826', b'', b'', b''],\n       [b'40380595', b'4093463', b'9588009', b'1073741826', b'', b'', b''],\n       [b'40380595', b'4093463', b'9588009', b'1073741826', b'', b'', b''],\n       [b'55798526', b'101458', b'1073741826', b'', b'', b'', b''],\n       [b'55798526', b'101458', b'1073741826', b'', b'', b'', b''],\n       [b'55798526', b'101458', b'1073741826', b'', b'', b'', b''],\n       [b'39247221', b'43725', b'479887', b'432971', b'', b'', b''],\n       [b'39247221', b'43725', b'479887', b'432971', b'', b'', b''],\n       [b'39247221', b'43725', b'479887', b'432971', b'', b'', b''],\n       [b'81230', b'87124', b'95538', b'55766129', b'55751139', b'', b''],\n       [b'238244', b'379576', b'857846', b'55778710', b'449749',\n        b'55789348', b''],\n       [b'696698', b'756562', b'460295', b'', b'', b'', b''],\n       [b'696698', b'756562', b'460295', b'', b'', b'', b''],\n       [b'668766', b'1357002', b'179846', b'', b'', b'', b''],\n       [b'238244', b'55797157', b'449749', b'55802521', b'55789348',\n        b'3743820', b'585124'],\n       [b'238244', b'55797157', b'449749', b'55802521', b'55789348',\n        b'3743820', b'585124'],\n       [b'238244', b'55797157', b'449749', b'55802521', b'55789348',\n        b'3743820', b'585124'],\n       [b'238244', b'585124', b'41263', b'3578887', b'449749', b'55718579',\n        b''],\n       [b'55776765', b'164339', b'102577', b'9590868', b'55747395',\n        b'41443783', b'9566472'],\n       [b'102674', b'4691486', b'55774851', b'', b'', b'', b''],\n       [b'81230', b'87124', b'95538', b'55766129', b'55751139', b'', b''],\n       [b'55780594', b'811192', b'5852709', b'55804072', b'55744355',\n        b'1073741828', b''],\n       [b'55780594', b'811192', b'5852709', b'55804072', b'55744355',\n        b'1073741828', b''],\n       [b'55780594', b'811192', b'5852709', b'55804072', b'55744355',\n        b'1073741828', b''],\n       [b'55780594', b'811192', b'5852709', b'55804072', b'55744355',\n        b'1073741828', b'']], dtype=object)>, 'pubtime': <tf.Tensor: id=651, shape=(30,), dtype=string, numpy=\narray([b'1541749143', b'1542686388', b'1542768269', b'1543989231',\n       b'1539776409', b'1539776409', b'1539776409', b'1539776409',\n       b'1532094659', b'1532094659', b'1532094659', b'1544419333',\n       b'1544419333', b'1544419333', b'1541066995', b'1542881440',\n       b'1542686827', b'1542686827', b'1540295949', b'1544490174',\n       b'1544490174', b'1544490174', b'1543524975', b'1540265114',\n       b'1541749245', b'1541066995', b'1542001417', b'1542001417',\n       b'1542001417', b'1542001417'], dtype=object)>, 'devid': <tf.Tensor: id=634, shape=(30,), dtype=string, numpy=\narray([b'866119038778727_460110425250266:460015696232580',\n       b'864291033627134_460030263473141',\n       b'865414032758614_460021357852587',\n       b'864289039373653_460002072248948:460029477299204',\n       b'863058038841924_', b'863058038841924_', b'863058038841924_',\n       b'863058038841924_', b'866934039706299_460002684384108',\n       b'866934039706299_460002684384108',\n       b'866934039706299_460002684384108',\n       b'5F82A2B9-D7FB-44F3-83C8-5D84C2534A73',\n       b'5F82A2B9-D7FB-44F3-83C8-5D84C2534A73',\n       b'5F82A2B9-D7FB-44F3-83C8-5D84C2534A73', b'867614025098823_',\n       b'414D0848-6C5B-4E4A-8723-A14F8BA6BEDE',\n       b'861910034907012_460029898438395',\n       b'861910034907012_460029898438395',\n       b'862322042161773_460026445014230',\n       b'867471031324234_460016228407389',\n       b'867471031324234_460016228407389',\n       b'867471031324234_460016228407389',\n       b'867519032714322_460022915894566', b'865176039147345_',\n       b'975DC2B1-8702-4F47-A0A6-F892B2999B36',\n       b'867772030257717_460028623838013',\n       b'862821032582823_460009420497226',\n       b'862821032582823_460009420497226',\n       b'862821032582823_460009420497226',\n       b'862821032582823_460009420497226'], dtype=object)>, 'province': <tf.Tensor: id=650, shape=(30,), dtype=int32, numpy=\narray([17,  0,  4,  5,  0,  0,  0,  0,  3,  3,  3,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0])>, 'city': <tf.Tensor: id=633, shape=(30,), dtype=string, numpy=\narray([b'170', b'', b'21', b'28', b'', b'', b'', b'', b'10', b'10', b'10',\n       b'', b'', b'', b'', b'', b'', b'', b'0', b'', b'', b'', b'', b'',\n       b'', b'39', b'', b'', b'', b''], dtype=object)>, 'profession': <tf.Tensor: id=649, shape=(30,), dtype=int32, numpy=\narray([0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 4, 0, 0, 0, 0])>, 'age': <tf.Tensor: id=624, shape=(30,), dtype=int32, numpy=\narray([15,  0, 34, 13,  0,  0,  0,  0, 13, 13, 13,  0,  0,  0,  0,  0,  0,\n        0,  0,  0,  0,  0,  0,  0,  0, 22,  0,  0,  0,  0])>, 'gender': <tf.Tensor: id=635, shape=(30,), dtype=string, numpy=\narray([b'1', b'', b'1', b'1', b'', b'', b'', b'', b'1', b'1', b'1', b'',\n       b'', b'', b'', b'', b'', b'', b'0', b'', b'', b'', b'', b'', b'',\n       b'1', b'', b'', b'', b''], dtype=object)>, 'cate1_weight_info': <tf.Tensor: id=628, shape=(30, 0), dtype=int32, numpy=array([], shape=(30, 0), dtype=int32)>, 'cate2_weight_info': <tf.Tensor: id=632, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'media_weight_info': <tf.Tensor: id=648, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'tag_weight_info': <tf.Tensor: id=655, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'cate1_ext_weight_info': <tf.Tensor: id=626, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'cate2_ext_weight_info': <tf.Tensor: id=630, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'media_ext_weight_info': <tf.Tensor: id=646, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'tag_ext_weight_info': <tf.Tensor: id=653, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'cate1_lst_weight_info': <tf.Tensor: id=627, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'cate2_lst_weight_info': <tf.Tensor: id=631, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'media_lst_weight_info': <tf.Tensor: id=647, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'tag_lst_weight_info': <tf.Tensor: id=654, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate1_weight_info': <tf.Tensor: id=638, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate2_weight_info': <tf.Tensor: id=641, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_media_weight_info': <tf.Tensor: id=644, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate1_ext_weight_info': <tf.Tensor: id=636, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate2_ext_weight_info': <tf.Tensor: id=639, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_media_ext_weight_info': <tf.Tensor: id=642, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate1_lst_weight_info': <tf.Tensor: id=637, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_cate2_lst_weight_info': <tf.Tensor: id=640, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>, 'hg_media_lst_weight_info': <tf.Tensor: id=643, shape=(30, 0), dtype=string, numpy=array([], shape=(30, 0), dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "for x in batch_data.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\nTensor(\"Shape:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_1:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_2:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_3:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_4:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_5:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_6:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_7:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_8:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_9:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_10:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_11:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_12:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_13:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_14:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_15:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_16:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_17:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_18:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_19:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_20:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_21:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_22:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_23:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_24:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_25:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_26:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_27:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_28:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_29:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_30:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_31:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_32:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_33:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_34:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_35:0\", shape=(1,), dtype=int32)\nTensor(\"Shape_36:0\", shape=(1,), dtype=int32)\nTensor(\"DecodeCSV:0\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:1\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:2\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:3\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:8\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:16\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:17\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:18\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:19\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:20\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:21\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:22\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:23\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:24\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:25\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:26\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:27\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:28\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:29\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:30\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:31\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:32\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:33\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:34\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:35\", shape=(30,), dtype=string)\nTensor(\"DecodeCSV:36\", shape=(30,), dtype=string)\n{'vids': <tf.Tensor 'SparseToDense:0' shape=(?, ?) dtype=string>, 'vidMedias': <tf.Tensor 'SparseToDense_1:0' shape=(?, ?) dtype=string>, 'vidCate1s': <tf.Tensor 'StringToNumber:0' shape=(?, ?) dtype=int32>, 'vidCate2s': <tf.Tensor 'SparseToDense_3:0' shape=(?, ?) dtype=string>, 'vid': <tf.Tensor 'DecodeCSV:4' shape=(30,) dtype=string>, 'media': <tf.Tensor 'DecodeCSV:5' shape=(30,) dtype=string>, 'cate1': <tf.Tensor 'DecodeCSV:6' shape=(30,) dtype=int32>, 'cate2': <tf.Tensor 'DecodeCSV:7' shape=(30,) dtype=string>, 'tag': <tf.Tensor 'SparseToDense_4:0' shape=(?, ?) dtype=string>, 'pubtime': <tf.Tensor 'DecodeCSV:9' shape=(30,) dtype=string>, 'devid': <tf.Tensor 'DecodeCSV:10' shape=(30,) dtype=string>, 'province': <tf.Tensor 'DecodeCSV:11' shape=(30,) dtype=int32>, 'city': <tf.Tensor 'DecodeCSV:12' shape=(30,) dtype=string>, 'profession': <tf.Tensor 'DecodeCSV:13' shape=(30,) dtype=int32>, 'age': <tf.Tensor 'DecodeCSV:14' shape=(30,) dtype=int32>, 'gender': <tf.Tensor 'DecodeCSV:15' shape=(30,) dtype=string>, 'cate1_weight_info': <tf.Tensor 'StringToNumber_1:0' shape=(?, ?) dtype=int32>, 'cate2_weight_info': <tf.Tensor 'SparseToDense_6:0' shape=(?, ?) dtype=string>, 'media_weight_info': <tf.Tensor 'SparseToDense_7:0' shape=(?, ?) dtype=string>, 'tag_weight_info': <tf.Tensor 'SparseToDense_8:0' shape=(?, ?) dtype=string>, 'cate1_ext_weight_info': <tf.Tensor 'SparseToDense_9:0' shape=(?, ?) dtype=string>, 'cate2_ext_weight_info': <tf.Tensor 'SparseToDense_10:0' shape=(?, ?) dtype=string>, 'media_ext_weight_info': <tf.Tensor 'SparseToDense_11:0' shape=(?, ?) dtype=string>, 'tag_ext_weight_info': <tf.Tensor 'SparseToDense_12:0' shape=(?, ?) dtype=string>, 'cate1_lst_weight_info': <tf.Tensor 'SparseToDense_13:0' shape=(?, ?) dtype=string>, 'cate2_lst_weight_info': <tf.Tensor 'SparseToDense_14:0' shape=(?, ?) dtype=string>, 'media_lst_weight_info': <tf.Tensor 'SparseToDense_15:0' shape=(?, ?) dtype=string>, 'tag_lst_weight_info': <tf.Tensor 'SparseToDense_16:0' shape=(?, ?) dtype=string>, 'hg_cate1_weight_info': <tf.Tensor 'SparseToDense_17:0' shape=(?, ?) dtype=string>, 'hg_cate2_weight_info': <tf.Tensor 'SparseToDense_18:0' shape=(?, ?) dtype=string>, 'hg_media_weight_info': <tf.Tensor 'SparseToDense_19:0' shape=(?, ?) dtype=string>, 'hg_cate1_ext_weight_info': <tf.Tensor 'SparseToDense_20:0' shape=(?, ?) dtype=string>, 'hg_cate2_ext_weight_info': <tf.Tensor 'SparseToDense_21:0' shape=(?, ?) dtype=string>, 'hg_media_ext_weight_info': <tf.Tensor 'SparseToDense_22:0' shape=(?, ?) dtype=string>, 'hg_cate1_lst_weight_info': <tf.Tensor 'SparseToDense_23:0' shape=(?, ?) dtype=string>, 'hg_cate2_lst_weight_info': <tf.Tensor 'SparseToDense_24:0' shape=(?, ?) dtype=string>, 'hg_media_lst_weight_info': <tf.Tensor 'SparseToDense_25:0' shape=(?, ?) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "batched = dataset.apply(tf.contrib.data.batch_and_drop_remainder(30))\n",
    "# batched = dataset.batch(batch_size, drop_remainder=True)\n",
    "batch_data = batched.map(parse_csv, num_parallel_calls=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=5)\n",
    "for x in dataset.take(1):\n",
    "    xx = tf.reshape(x, [1, ])\n",
    "    print(tf.shape(xx))\n",
    "    sparse_tensor = tf.string_split(xx, delimiter=\"\\t\")\n",
    "    too = tf.sparse_to_dense(sparse_tensor.indices,\n",
    "                       sparse_tensor.dense_shape,\n",
    "                       sparse_tensor.values,\n",
    "                       default_value='')\n",
    "    tooo = tf.reshape(too, [-1])\n",
    "    print(tooo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['clks', 'cat1s', 'cat2s', 'tags', 'devid', 'age', 'gender','province', 'city',\n",
    "                    'profession', 'dev_mode', 'os_type', 'network',\n",
    "                    'cate1_weight_info', 'cate2_weight_info', 'media_weight_info',\n",
    "                    'tag_weight_info', 'cate1_ext_weight_info', 'cate2_ext_weight_info', 'media_ext_weight_info',\n",
    "                    'tag_ext_weight_info', 'cate1_lst_weight_info', 'cate2_lst_weight_info',\n",
    "                    'media_lst_weight_info', 'tag_lst_weight_info',\n",
    "                    \n",
    "                    'vid', 'media', 'cate1', 'cate2', 'tag', 'pubtime', 'quality', 'duration', 'algid', 'label']\n",
    "_CSV_COLUMN_DEFAULTS = [[''], [''], [''],[''], [''], [-1], [''], [0], [''],\n",
    "                        [''], [''], [''], [''],\n",
    "                        [''], [''], [''],\n",
    "                        [''], [''], [''],[''],\n",
    "                        [''], [''], [''],\n",
    "                        [''], [''],\n",
    "                        \n",
    "                        [''], [''],[0],[''],[''],[0],[0],[0],[''],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_path, num_parallel_calls):\n",
    "    dataset = tf.data.TextLineDataset(input_path)\n",
    "    (features, labels) = dataset.map(parse_csv, num_parallel_calls=num_parallel_calls)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path=\"D:\\\\workPlace\\\\gitCode\\\\python-lorineluo-dev\\\\src\\\\main\\\\python\\\\prerank\\\\data\\\\20190520\"\n",
    "dataset = tf.data.TextLineDataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'i08667lnou9,j0867rw7lhx,m08668dzg2o,p0501gc1yun,w0862xn9te7,z0861krz8jl,a0647lzhdds,e086225gzap,v0868mdd611,e08685z0bka,o0867oultox,b0867g3yikx,a05569rqafh,z0683g9x5yx,n0866rqor8y,k0848zyvw1u,r0864dxnjf1,s0859isg39u,u0861nz6o79,k0865zjvi9p,z0864zmamff,n0865sbgbz0,o0867qux6xk,t08670fy5yk,k0860wbkr7c,w08622eqj7f,x0865b8h1ne,f086890gfmj,v0866p4n2fl,j0861f02z25,e08571c4g3o\\t1494464,1494464,1538931,1494464,1494464,1494464,1494464,1494455,1494464,1494464,1494464,1494464,1494464,1494464,1538931,1494462,1494462,1494455,1494455,1494455,1494455,1494456,1494456,1494448,1494464,1494464,1494464,1494448,1494448,1494448,1494462\\t1494428,1494428,1538936,1494428,1494428,1496639,1494428,1494498,1494428,1494428,1494428,1494428,1494428,1494428,1538936,1494520,1494485,1494498,1494498,1494498,1494498,1494510,1494510,1494521,1494428,1494428,1496639,1494521,1494521,1494521,1494520\\t55735124,97409,55790915,55751139,55745368,55735124,97409,612476,55790915,55751139,55745368,366521,820612,101500,102538,4243235,41443783,37771768,3322140,50020925,36204,612476,55751139,55745368,193601,235980,55735180,55750423,55751139,55745368,471201,55757929,490886,3322140,50020925,36204,612476,774992,55745368,433186,849194,9484261,687320,631490,513596,55818697,55735124,29405,235806,55790915,55751139,55745368,55735124,36204,29405,280639,55790915,55751139,55745368,55735124,97409,612476,55790915,55751139,55745368,55735124,97409,276178,55766985,55790915,55751139,55745368,35912614,276178,97409,55766985,55751139,427931,83194,612476,55790915,55751139,55745368,365350,101500,102538,4243235,41443783,37771768,55768597,102538,101500,55818620,380440,377709,101524,55818592,433186,9484261,687320,631490,526834,560598,55818697,433186,269812,164328,365149,9484261,687320,631490,513596,55818697,9484261,269812,623718,433186,3482453,518106,513596,631490,433186,178436,164328,269812,9484261,687320,631490,513596,55818697,55768597,102538,101500,55818620,4910483,591983,555574,1357891,706193,837621,9498105,55750783,55745993,269812,191714,45202,55766985,55751139,55745368,55818483,13308555,280252,26598,55766985,55751139,55745368,55818483,55735124,36204,29405,55790915,55751139,55745368,55750783,387585,55834284,526834,461143,645952,55834284,461143,55750783,526834,55811793,100757,55745993,55834284,15767705,102538,101500,40593754\\t868320042118169_460031539502454\\t11\\t1\\t23\\t0\\t0\\tAUM-AL00\\tandroid\\t4\\t1494462,1494464,1494455,1494448,1538931\\t1494428,1496639,1494498,1494521,1538936\\t5749824,15416958,5777718,5640187,5642187\\t3322140,9484261,55790915,50020925,55735124,55745368,55750783,55751139,687320,631490,612476,269812,36204,513596,433186,55818697,37771768,101500,102538,4243235,41443783,235806,55791757,55766985,3482453,29405,97409,526834,774992,164328,461143,486785,518106,178436,55834284,100757,55757929,55745993,55818620,55768597,55818592,1357891,380440,55768114,55818483,276178,623718,9498105,849194,55811793\\t1528271,8060000,8140000,1494450,1494458\\t1494422,1494541,1494504,1538935,1494519\\t7075378,5547163,15415179,5613912,5606964\\t461143,36204,235806,29405,225375,97409,269812,55759498,55773336,164328,6076694,161780,55783860,55784566,513596,486350,4965291,4269984,176968,486785\\t1494464,1494455,1494448,1494462,1538931\\t1494428,1494498,1494521,1494520,1496639\\t5749824,13144005,5256612,6959389,10856533\\t55745368,55751139,55790915,55735124,9484261,433186,631490,101500,102538,97409,55818697,687320,513596,612476,526834,269812,55750783,55834284,29405,461143,36204,55745993,164328,774992,37771768,41443783,4243235,820612,366521,55757929,490886,471201,849194,427931,83194,101524,377709,380440,55818592,178436,555574,591983,706193,837621,1357891,9498105,4910483,15767705,40593754,486785\\tk0866phd227\\t5936020\\t1494455\\t1494498\\t627770,731066,513596,631490\\t1556714629\\t0\\t110\\t100400003,100500072\\t0', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for t in dataset.take(2):\n",
    "    print(t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = tf.decode_csv(t, record_defaults=_CSV_COLUMN_DEFAULTS,\n",
    "                            field_delim='\\t', na_value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=82, shape=(), dtype=string, numpy=b'i08667lnou9,j0867rw7lhx,m08668dzg2o,p0501gc1yun,w0862xn9te7,z0861krz8jl,a0647lzhdds,e086225gzap,v0868mdd611,e08685z0bka,o0867oultox,b0867g3yikx,a05569rqafh,z0683g9x5yx,n0866rqor8y,k0848zyvw1u,r0864dxnjf1,s0859isg39u,u0861nz6o79,k0865zjvi9p,z0864zmamff,n0865sbgbz0,o0867qux6xk,t08670fy5yk,k0860wbkr7c,w08622eqj7f,x0865b8h1ne,f086890gfmj,v0866p4n2fl,j0861f02z25,e08571c4g3o'>, <tf.Tensor: id=83, shape=(), dtype=string, numpy=b'1494464,1494464,1538931,1494464,1494464,1494464,1494464,1494455,1494464,1494464,1494464,1494464,1494464,1494464,1538931,1494462,1494462,1494455,1494455,1494455,1494455,1494456,1494456,1494448,1494464,1494464,1494464,1494448,1494448,1494448,1494462'>, <tf.Tensor: id=84, shape=(), dtype=string, numpy=b'1494428,1494428,1538936,1494428,1494428,1496639,1494428,1494498,1494428,1494428,1494428,1494428,1494428,1494428,1538936,1494520,1494485,1494498,1494498,1494498,1494498,1494510,1494510,1494521,1494428,1494428,1496639,1494521,1494521,1494521,1494520'>, <tf.Tensor: id=85, shape=(), dtype=string, numpy=b'55735124,97409,55790915,55751139,55745368,55735124,97409,612476,55790915,55751139,55745368,366521,820612,101500,102538,4243235,41443783,37771768,3322140,50020925,36204,612476,55751139,55745368,193601,235980,55735180,55750423,55751139,55745368,471201,55757929,490886,3322140,50020925,36204,612476,774992,55745368,433186,849194,9484261,687320,631490,513596,55818697,55735124,29405,235806,55790915,55751139,55745368,55735124,36204,29405,280639,55790915,55751139,55745368,55735124,97409,612476,55790915,55751139,55745368,55735124,97409,276178,55766985,55790915,55751139,55745368,35912614,276178,97409,55766985,55751139,427931,83194,612476,55790915,55751139,55745368,365350,101500,102538,4243235,41443783,37771768,55768597,102538,101500,55818620,380440,377709,101524,55818592,433186,9484261,687320,631490,526834,560598,55818697,433186,269812,164328,365149,9484261,687320,631490,513596,55818697,9484261,269812,623718,433186,3482453,518106,513596,631490,433186,178436,164328,269812,9484261,687320,631490,513596,55818697,55768597,102538,101500,55818620,4910483,591983,555574,1357891,706193,837621,9498105,55750783,55745993,269812,191714,45202,55766985,55751139,55745368,55818483,13308555,280252,26598,55766985,55751139,55745368,55818483,55735124,36204,29405,55790915,55751139,55745368,55750783,387585,55834284,526834,461143,645952,55834284,461143,55750783,526834,55811793,100757,55745993,55834284,15767705,102538,101500,40593754'>, <tf.Tensor: id=86, shape=(), dtype=string, numpy=b'868320042118169_460031539502454'>, <tf.Tensor: id=87, shape=(), dtype=int32, numpy=11>, <tf.Tensor: id=88, shape=(), dtype=string, numpy=b'1'>, <tf.Tensor: id=89, shape=(), dtype=int32, numpy=23>, <tf.Tensor: id=90, shape=(), dtype=string, numpy=b'0'>, <tf.Tensor: id=91, shape=(), dtype=string, numpy=b'0'>, <tf.Tensor: id=92, shape=(), dtype=string, numpy=b'AUM-AL00'>, <tf.Tensor: id=93, shape=(), dtype=string, numpy=b'android'>, <tf.Tensor: id=94, shape=(), dtype=string, numpy=b'4'>, <tf.Tensor: id=95, shape=(), dtype=string, numpy=b'1494462,1494464,1494455,1494448,1538931'>, <tf.Tensor: id=96, shape=(), dtype=string, numpy=b'1494428,1496639,1494498,1494521,1538936'>, <tf.Tensor: id=97, shape=(), dtype=string, numpy=b'5749824,15416958,5777718,5640187,5642187'>, <tf.Tensor: id=98, shape=(), dtype=string, numpy=b'3322140,9484261,55790915,50020925,55735124,55745368,55750783,55751139,687320,631490,612476,269812,36204,513596,433186,55818697,37771768,101500,102538,4243235,41443783,235806,55791757,55766985,3482453,29405,97409,526834,774992,164328,461143,486785,518106,178436,55834284,100757,55757929,55745993,55818620,55768597,55818592,1357891,380440,55768114,55818483,276178,623718,9498105,849194,55811793'>, <tf.Tensor: id=99, shape=(), dtype=string, numpy=b'1528271,8060000,8140000,1494450,1494458'>, <tf.Tensor: id=100, shape=(), dtype=string, numpy=b'1494422,1494541,1494504,1538935,1494519'>, <tf.Tensor: id=101, shape=(), dtype=string, numpy=b'7075378,5547163,15415179,5613912,5606964'>, <tf.Tensor: id=102, shape=(), dtype=string, numpy=b'461143,36204,235806,29405,225375,97409,269812,55759498,55773336,164328,6076694,161780,55783860,55784566,513596,486350,4965291,4269984,176968,486785'>, <tf.Tensor: id=103, shape=(), dtype=string, numpy=b'1494464,1494455,1494448,1494462,1538931'>, <tf.Tensor: id=104, shape=(), dtype=string, numpy=b'1494428,1494498,1494521,1494520,1496639'>, <tf.Tensor: id=105, shape=(), dtype=string, numpy=b'5749824,13144005,5256612,6959389,10856533'>, <tf.Tensor: id=106, shape=(), dtype=string, numpy=b'55745368,55751139,55790915,55735124,9484261,433186,631490,101500,102538,97409,55818697,687320,513596,612476,526834,269812,55750783,55834284,29405,461143,36204,55745993,164328,774992,37771768,41443783,4243235,820612,366521,55757929,490886,471201,849194,427931,83194,101524,377709,380440,55818592,178436,555574,591983,706193,837621,1357891,9498105,4910483,15767705,40593754,486785'>, <tf.Tensor: id=107, shape=(), dtype=string, numpy=b'k0866phd227'>, <tf.Tensor: id=108, shape=(), dtype=string, numpy=b'5936020'>, <tf.Tensor: id=109, shape=(), dtype=int32, numpy=1494455>, <tf.Tensor: id=110, shape=(), dtype=string, numpy=b'1494498'>, <tf.Tensor: id=111, shape=(), dtype=string, numpy=b'627770,731066,513596,631490'>, <tf.Tensor: id=112, shape=(), dtype=int32, numpy=1556714629>, <tf.Tensor: id=113, shape=(), dtype=int32, numpy=0>, <tf.Tensor: id=114, shape=(), dtype=int32, numpy=110>, <tf.Tensor: id=115, shape=(), dtype=string, numpy=b'100400003,100500072'>, <tf.Tensor: id=116, shape=(), dtype=int32, numpy=0>]\n"
     ]
    }
   ],
   "source": [
    "print (columns)\n",
    "features = dict(zip(CSV_COLUMN_NAMES, columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=82, shape=(), dtype=string, numpy=b'i08667lnou9,j0867rw7lhx,m08668dzg2o,p0501gc1yun,w0862xn9te7,z0861krz8jl,a0647lzhdds,e086225gzap,v0868mdd611,e08685z0bka,o0867oultox,b0867g3yikx,a05569rqafh,z0683g9x5yx,n0866rqor8y,k0848zyvw1u,r0864dxnjf1,s0859isg39u,u0861nz6o79,k0865zjvi9p,z0864zmamff,n0865sbgbz0,o0867qux6xk,t08670fy5yk,k0860wbkr7c,w08622eqj7f,x0865b8h1ne,f086890gfmj,v0866p4n2fl,j0861f02z25,e08571c4g3o'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['clks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor=tf.string_split([features['clks']], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= tf.sparse_to_dense(\n",
    "                sparse_tensor.indices,\n",
    "                sparse_tensor.dense_shape,\n",
    "                sparse_tensor.values,\n",
    "                default_value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n[[b'i08667lnou9' b'j0867rw7lhx' b'm08668dzg2o' b'p0501gc1yun'\n  b'w0862xn9te7' b'z0861krz8jl' b'a0647lzhdds' b'e086225gzap'\n  b'v0868mdd611' b'e08685z0bka' b'o0867oultox' b'b0867g3yikx'\n  b'a05569rqafh' b'z0683g9x5yx' b'n0866rqor8y' b'k0848zyvw1u'\n  b'r0864dxnjf1' b's0859isg39u' b'u0861nz6o79' b'k0865zjvi9p'\n  b'z0864zmamff' b'n0865sbgbz0' b'o0867qux6xk' b't08670fy5yk'\n  b'k0860wbkr7c' b'w08622eqj7f' b'x0865b8h1ne' b'f086890gfmj'\n  b'v0866p4n2fl' b'j0861f02z25' b'e08571c4g3o']], shape=(1, 31), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,0]])\n",
    "logits = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "y_pred = tf.nn.sigmoid(logits)\n",
    "E1 = -y*np.log(y_pred)-(1-y)*np.log(1-y_pred)\n",
    "y = np.array(y).astype(np.float64)  #label是float64\n",
    "E2 = tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "print(y_pred)\n",
    "print(E1)\n",
    "print(E2)\n",
    "tf.reduce_sum(E2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n[[ 0.62454749]\n [ 0.62302509]\n [ 0.68995736]\n [ 0.65695291]\n [ 0.66749906]\n [ 0.66869016]], shape=(6, 1), dtype=float64)\n[[ 0.9796233 ]\n [ 0.47316849]\n [ 0.37112548]\n [ 0.42014293]\n [ 1.1011126 ]\n [ 0.40243446]]\ntf.Tensor(\n[[ 0.9796233 ]\n [ 0.47316849]\n [ 0.37112548]\n [ 0.42014293]\n [ 1.1011126 ]\n [ 0.40243446]], shape=(6, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "logits=np.array([[0.508895397],[0.502408147],[0.799919963],[0.64974463],[0.696895301],[0.702266812]])\n",
    "y=np.array([[0],[1],[1],[1],[0],[1]])\n",
    "y_pred = tf.nn.sigmoid(logits)\n",
    "E1 = -y*np.log(y_pred)-(1-y)*np.log(1-y_pred)\n",
    "y = np.array(y).astype(np.float64)  #label是float64\n",
    "E2 = tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "print(y_pred)\n",
    "print(E1)\n",
    "print(E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2, 3, 4], [2,3,4,5]], dtype=tf.float32)\n",
    "b = tf.reshape(a, [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(8, 1), dtype=float32, numpy=\narray([[ 1.],\n       [ 2.],\n       [ 3.],\n       [ 4.],\n       [ 2.],\n       [ 3.],\n       [ 4.],\n       [ 5.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
